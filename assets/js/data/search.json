[
  
  {
    "title": "2022 個人年度回顧",
    "url": "/blog/2022-review/",
    "categories": "Others",
    "tags": "Personal",
    "date": "2022-12-31 20:25:20 +0800",
    





    "snippet": "2022 是一個變化多端的一年，不管是職場上還是生活上都嘗試了許多新事物，嘗試改變以往的習慣、心態及生活方式，慢慢地調整成自己的目標，整體來說是一個具有好的轉折點的一年。2022 回顧生活  報名健身房跟教練課，調整飲食跟維持體態，了解到許多飲食控制、肌肉以及伸展相關知識，也意識到以前訓練方式很多都是錯誤的，還好能即時挑整。  報名了拳擊課，很舒壓，但是後來因為身體因素，上了幾堂後還是忍痛取消，這是我覺得最可惜的事。  參加了英文寫作跟口說班，每個禮拜都花很多時間在寫作業，非常累，但感覺英文程度跟以前比起來有進步一些，目標是希望之後部落格文章能使用英文撰寫。  找到了能互相扶持的人，每個月到處踩雷踩點，為 2022 添加了許多豐富的色彩。  第一次跑到台中跨年看煙火，上一次衝到別縣市跨年應該是大學時期的時候了，頓時覺得己年輕了起來。  今年有幸能跟社群夥伴 Frank Lin 一起到 COSCUP 2022 x KCD Taiwan 分享『那些年我們在開源社群的日子 Cloud Native Taiwan』，帶大家了解如何參與開源社群。工作  今年開始在前公司轉換部門，變成內部協助 RD 開發的 System Engineer，專注設計產品架構以及針對系統進行測試，改成不用面對客戶壓力少了許多，也多出更多時間可以好好專研相關技術以及維持 Work-Life Balance。  遭遇職涯第一次的部門危機，見識了職場混亂及黑暗面，趁著這個機會離開了待了快三年的前公司。  有幸錄取了目前公司的 Platform Consultant 職位，能獲得這個機會真的是付出了很多努力還有許多貴人的幫助，對我而言是一個職涯的里程碑，也是一個很大的挑戰。2023 展望  持續控制飲食跟維持體態，目標是體脂到 10~11%。  持續加強英文能力，達到溝通及寫作上都能夠流暢的程度。  盡快 Pick up 起新公司的職務內容，提升自己的 credit。  更新停擺已久的部落格，強迫自己多撰寫文章。  完成先前未完成的專業認證。  多與人交流，提升自身人脈。  維持 Work-life Balance，加強時間管理跟分配，留給更多的時間做自己想做的事以及休閒。  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "COSCUP 2022 - 那些年我們在開源社群的日子 - Cloud Native Taiwan",
    "url": "/blog/coscup2022-the-journey-of-opensource-community-cntug/",
    "categories": "Others",
    "tags": "conference",
    "date": "2022-08-01 00:00:00 +0800",
    





    "snippet": "COSCUP x KCD Taiwan 2022今年 COSCUP 2022 終於變回實體線下活動，還是線下活動面對面比較可以與人交流，也遇到了許多好久不見得熟面孔，光是敘舊就聊不完了 xD這次我們社群 CNTUG 申請主辦台灣地區的 Kubernetes Community Day (KCD)，KCD 為 CNCF 官方的活動，性質跟 KubeConf 有點不太一樣，KCD 主要是藉由各地區當地的社群來推廣 Cloud Native 以及 Kubernetes 文化的一個活動，所以會由各國家地區的社群來主持這個活動，而台灣地區的就是 KCD Taiwan。今年 KCD Taiwan 跟 COSCUP 2022 一起合作，所以可以看到 COSCUP 2022 官網會有 COSCUP x KCD Taiwan 2022 以及吉祥物，而有一個主議程軌 (7/30 AU 視聽館)是專門給 KCD Taiwan 的，有興趣的朋友可以參考議程表。Talk - 那些年我們在開源社群的日子 Cloud Native Taiwan今年很榮幸跟社群夥伴 Frank Lin 一起投稿開源新手村，投稿題目是 「那些年我們在開源社群的日子 - Cloud Native Taiwan」，主要是以社群志工角度，介紹我們對於參與開源社群的一些想法，整理一些建議給想參與社群的會眾。我們認為社群就是 一群志同道合宅宅聚集而成的團體，目的為分享、學習、推廣、交流以及貢獻開源技術，有點類似學校的社團一樣，大家對於共同領域有熱情，並一起投入進去的感覺。如何參與社群?在此 Talk 中我們整理了四個參與社群的簡單步驟:  尋找動機  尋找管道  參與社群  支持與貢獻尋找動機顧名思義，就是尋找你想參與社群的目的或是動機，這裡可以再細分成兩步。第一步可以先找出你有興趣的領域，例如系統、程式、硬體、資安、開源、產品或是平台都可以，也可以多個。找到有興趣的領域後，第二步就是尋找你的動機跟目的，想增進技術？想擴展人脈? 想交流或是請教技術？想要貢獻技術？還是想要增加眼界？這些都可以變成你加入社群的動機，可以統整下來，並以這些目標前進，但還是需要注意，目標已不影響他人為主！尋找管道有了動機跟目的後，可以開始尋找資源，透過各種管道找到社群的資訊，這邊推薦幾種常見的管道:  台灣開源社群推廣目錄  社群平台 (Facebook、Twitter、Slack、Telegram 等等)  社群官方網站  各式研討會 (SITCON/COSCUP/HITCON/iThome…)  親朋好友或是實驗室跟學校社團可以根據關鍵字或是地區來進行搜索，目前台灣有非常多的社群，可以直接參與。在這些方法中我個人很推薦參與研討會，參與研討會可以讓你見識不同領域的新技術以及認識各式各樣的公司或是社群，是一個很好的機會與人交流以及尋找自己的方向的地方，除了可以聽聽演講以外，許多社群或是公司也會有擺攤、Workshop 活動，可以多加參與進一步暸解社群以及文化。如果自己想要的領域比較冷門或是還沒有相關社群時，可以考慮自己創立一個社群，也許有人覺得創立社群很困難，一開始就要多大多複雜的組織架構，但其實回歸到最原始的定義，社群只是『一群對同樣領域有熱情的人組成的團體』，所以其實是可以從小團體開始經營，例如小型讀書會、聚會或是可以從建立社群平台粉專開始，等到穩定之後，再慢慢擴大規模，例如從幾個朋友之間，變成實驗室，再變成系上或是學校，甚至還可以開始跟其他社群合作或是投稿研討會增加社群能見度，都是不錯的方式。參與社群找到適合的社群後，就可以積極的參與各項社群活動，包括:  社群活動(Meetup/Conference/Workshop…)  與其他會眾交流  於各式活動支持社群攤位  加入社群平台社團交流  旁聽社群定期會議  擔任講者分享經驗 (增加自己的能見度)可以多參加不同的社群，了解不同社群文化以及經營，也可以多方學習不同種類的技術，多與人交流，也許可以獲得不錯的寶貴經驗。不過大多數人是比較害羞內向的，在參與社群時，可能比較難以跟其他人交流，在這裡分享一個小技巧，從請教問題開始切入。一開始可以先當聽眾就好，不用刻意要找人聊天，專心參與以及聽分享，也許某一次的分享的內容你剛好很有共鳴或是有疑問，就可以去請教講者，這就是一個很好的交流切入點，有時候在與講者討論時，其他會眾也加入一起討論，就可以趁這機會多認識人，慢慢的在交流上就會更有自信，也可以提升人脈。擔任志工若有閒暇之餘，也可以擔任社群志工，為社群經營盡一份力，志工主要負責以下這些項目:  協助籌辦各式活動  協助尋找講者  參與社群定期會議  管理社群相關營運事務 (社團、官方網站)由於經營社群會佔用到一些個人的時間，因此可以根據自身狀況盡力協助，志工之間彼此互相 Cover。如何支持及貢獻開源技術社群在參與社群一段時間後，可以選擇協助支持或是貢獻開源技術社群，支持有許多種形式，可以選擇最適合自己的方式:  積極社群活動 (Meetup/Conference/Workshop…)  使用及推廣開源技術  貢獻專案，成為 Contributor 或是 Member  於各式活動分享相關專案或技術經驗  擔任志工協助經營社群  贊助社群參與社群後對生活及職涯的影響參與社群除了能提升專業、自信以及能見度以外，我個人認為最重要的是人脈，能認識許多志同道合的朋友以及業界的夥伴，這不管在未來職涯還是生活上都很有幫助。若是參與志工，更能學習到如何組織活動、與其他人溝通及協同作業，這些都是實用且寶貴的經歷。套用社群朋友的一句話 社群就是一個很大的「舞台」，這個舞台提供了許多能夠讓人分享、交流以及貢獻的機會，並在這些過程中，不斷學習精進，透過社群內部的交流以及社群與社群間交流，互相學習補足各領域不足的資訊，讓整個社群圈變成一個知識共同體，讓技術不斷向邁進，這是我認為社群最棒的文化。Reference  開源社群推廣目錄  OCF - 社群專案  [王景弘] 談談COSCUP：讓整個社群圈變成一個知識共同體。  用社群實踐開源精神，Denny 不平凡的技術社群人生－專訪 SITCON 共同發起人 Denny Huang  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "ActiveMQ 5 Shared File System Master Slave",
    "url": "/blog/activemq5-shared-file-system-master-slave/",
    "categories": "Others",
    "tags": "activemq, master-slave, high availability",
    "date": "2022-04-22 07:14:58 +0800",
    





    "snippet": "ActiveMQ 5 在 High Availability (HA) 上分成兩種角色: master 和 slave ，類似 Active-Standby mode。在一般情況只會有 master 處理 Request，slave 待命，只有當 master 異常時，slave 才會接手這些動作。一般 ActiveMQ 都是把資料存在記憶體裡面，但是當 Broker 掛掉後，記憶體裡存放的 Message 會消失，因此在 HA 的概念就是要想辦法把 Message 變成 Persistent Data 存在 Disk，然後當 Broker 恢復時或是其他 Broker 接手時，可以直接存取這個 Persistent Data 來接手處理 Message。ActiveMQ 5 HA 分成兩種方式:  Shared File System Master Slave (Share Filesystem)  JDBC Master Slave (Share Database)本篇文章主要會探討的是 ActiveMQ 5 的 Shared File System Master Slave 模式。Shared File System Master Slave Introduction這個模式是會將 ActiveMQ 的 Persistent Data (Status 或 Message) 儲存在 Shared File System (如 NFS 或是 SAN)，再讓其他 ActiveMQ 掛載 Shared File System，讓全部 ActiveMQ 節點共同擁有這些資料。在開始實作前，先介紹一下運作機制。ActiveMQ 可以在 activemq.xml 的 persistenceAdapter 啟用 Local Database - KahaDB 來儲存 Persistent Data，ActiveMQ 會把 Message 存成 Log 檔存放在 Broker Local 的  KahaDB 目錄裡，預設都不改設定的話 KahaDB 位置為 ${activemq.data}/kahadb 也就是 ActiveMQ 目錄底下的 data/kahadb。        &amp;lt;persistenceAdapter&amp;gt;            &amp;lt;kahaDB directory=&quot;${activemq.data}/kahadb&quot;/&amp;gt;        &amp;lt;/persistenceAdapter&amp;gt;而在 Shared File System Master Slave 模式下，會把 Shared File System Volume 掛載到 KahaDB 目錄裡，如此一來 Master 跟所有 Slave ActiveMQ 節點都會取得同一個 KahaDB 資料，且這種方式會整合 Lock 機制，先搶到存取權的節點將會變成 Master，而其他結點就會變成 Slave， Slave 狀態的節點大部分服務都不會啟動，只會啟動一個很簡單的 Java 檔，定期檢查 KahaDB 是否已經被 Release，如有被 Release，就會啟動全部服務搶先變成 Master。      啟用時，只會有一台 Master 存在，其他搶輸的為 Slave (在此 Database1 為 KahaDB)        當 Master 異常並 Release KahaDB 後，其他 Slave 會爭奪變成新的 Master，接手原本的工作  圖片來源: ActiveMQ - The Failover Transport  在這種模式下只能有一個 Master，但可以有多個 Slave (1~N)。Implement以下為環境資訊:  Broker A Node          192.168.89.131:61616      ActiveMQ 5.16.4      Ubuntu 20.04 LTS      JMS Protocol        Broker B Node          192.168.89.132:61616      ActiveMQ 5.16.4      Ubuntu 20.04 LTS      JMS Protocol        Broker C Node          192.168.89.133:61616      ActiveMQ 5.16.4      Ubuntu 20.04 LTS      JMS Protocol        NFS Server (192.168.89.134)  如果要用 NFS 要用 NFSv4 不要用 NFSv3 會有問題，可查看 Official - Shared File System Master Slave  NFS Server 建置方式有相當多種，可以參考 Ubuntu 20.04 中配置NFS服務 ，在此不特別闡述  下載 ActiveMQ 5.16.4    $ wget https://archive.apache.org/dist/activemq/5.16.4/apache-activemq-5.16.4-bin.tar.gz$ tar zxvf apache-activemq-5.16.4-bin.tar.gz$ cd apache-activemq-5.16.4        三台 Broker Node 都建立一個 /mnt/KahaDB 目錄並掛載 NFS Volume，這個目錄就是用來存放 KahaDB Data。    $ mmkdir -p /mnt/kahaDB$ mount -t nfs4 -o proto=tcp,port=2049 192.168.89.134:/nfs /mnt/kahaDB/        接著修改三台 activemq.xml，設定 kahaDB 目錄位置。    $ vim apache-activemq-5.16.4/conf/activemq.xml        將 persistenceAdapter 改成如下         &amp;lt;persistenceAdapter&amp;gt;         &amp;lt;kahaDB directory=&quot;/mnt/kahaDB&quot;/&amp;gt;     &amp;lt;/persistenceAdapter&amp;gt;        接著就可以啟動三台 ActiveMQ Broker。    $ cd apache-activemq-5.16.4/bin/$ ./activemq start            啟動後可以發現只有 Broker C 真正有啟動服務 (8161 port, 61616 port)，Broker A 跟 Broker B 都只有啟動一隻 java 程式而已，表示 Broker C 為 Master，其他兩台為 Slave。Broker ABroker BBroker C    查看 Broker A 跟 Broker B Log (apache-activemq-5.16.3/data/acrivemq.log)，可以發現該台 Broker 為 Slave Mode。    2022-01-10 08:34:29,383 | INFO  | Refreshing org.apache.activemq.xbean.XBeanBrokerFactory$1@7cc0cdad: startup date [Mon Jan 10 08:34:29 UTC 2022]; root of context hierarchy | org.apache.activemq.xbean.XBeanBrokerFactory$1 | main2022-01-10 08:34:31,638 | INFO  | Using Persistence Adapter: KahaDBPersistenceAdapter[/mnt/kahaDB] | org.apache.activemq.broker.BrokerService | main2022-01-10 08:34:31,667 | INFO  | Database /mnt/kahaDB/lock is locked by another server. This broker is now in slave mode waiting a lock to be acquired | org.apache.activemq.store.SharedFileLocker | main        接著在 Producer 及 Consumer 設定 Failover Transport，這樣 Producer/Consumer 就會自動連上可以使用的 ActiveMQ，並且在 ActiveMQ 異常時，自動 Failover 切換連線到其他台。在此 HA 模式下，由於只有 Broker C 目前是有啟用 61616 port 的，因此只會連到 Broker C。    ... ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(&quot;failover:(tcp://192.168.89.131:61616,tcp://192.168.89.132:61616,tcp://192.168.89.133:61616)&quot;);...              Client 程式範例可以參考 Cross Language Clients。        完成後設定後，可以測試執行 apache-activemq-5.16.4/examples/openwire/java 目錄裡的範例程式傳送  Message (1000 筆)，這時 Client 會連到 Broker C。    $ java -cp target/openwire-example-0.1-SNAPSHOT.jar example.Publisher        可以看到 Broker C 裡面有 1000 筆 Message    接著執行 Consumer 程式，會連到 Broker C，然後開始取資料    $ java -cp target/openwire-example-0.1-SNAPSHOT.jar example.Listener            取到一半把 Broker C 關閉掉，模擬異常    ./activemq stop              如果 Consumer 接收 Message 過快的話，可以試著在程式加 sleep 機制，讓他放慢速度，比較好測試            大約等幾秒可以看到 Broker B 服務啟動了並接手了工作，變成 Master，然後 Consumer 會改成連至 Broker B，然後繼續從 Queue 取沒取完的 Message。     完成。Reference  ActiveMQ - The Failover Transport  ActiveMQ - Shared File System Master Slave  ActiveMQ - Clustering  Cross Language Clients  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "MariaDB Master-Slave Replication with MaxScale",
    "url": "/blog/mariadb-master-slave-replication-with-maxscale/",
    "categories": "Database",
    "tags": "mariadb, high availability",
    "date": "2022-03-05 20:24:21 +0800",
    





    "snippet": "最近因工作關係剛好研究到 MariaDB High Availability (HA) 機制，因此本篇整理一下 MariaDB Master-Slave Replication 的相關筆記。在一個系統環境裡，資料庫通常扮演著很重要的角色，主要負責存放系統的一些紀錄或是使用者的資料，因此資料庫的備援/高可用性 (High Availability)以及負載平衡 (Load Balancing) 就變得相當重要。目前 MariaDB 針對 High Availability 有以下常見的幾種方式:  Master-Slave Replication         (A-S Mode)  Master-Master Replication       (A-A Mode)  Galera Cluster Master-Master (A-A Mode)  Galera Cluster Master-Slave    (A-S Mode)本篇文章主要會探討的是最傳統的方式 Master-Slave Replication 。Master-Slave ReplicationMaster-Slave Replication 主要是將多台 MariaDB 組成 Cluster，而這個 Cluster 裡，會有一台 MariaDB 扮演 Master 的角色，而其他 1~n 台會扮演著 Slave 的角色，Master  主要負責的動作為Read-Write；Slave 則負責 Read 以及同步 Master 的所有操作。以下為最常見的架構，通常 Master 只會有一台，然後會有多台 Slave 不斷同步 Master 的工作，當 Master 掛掉時，管理者可以將 Slave 轉換成 Master 取代 Master 動作。圖片來源: Replication Overview因此在這種 Master-Slave Replication 架構下:  只能有一台 Master 存在，Master 可以處理 Read-Write 工作  可以有多台 Slave 存在，Slave 可以處理 Read 工作或是單純 Standby  Slave 會不斷跟 Master 同步資料  支援 Read HA + LoadBalancing  支援 Write HA 但不支援 Load Balancing  💡 如果要考量 Write Load Balancing，就必須要有多台 Master 同時運作的情境，這種情境就要改使用 Master-Master Replication 或是 MariaDB Galera Cluster。同步機制圖片來源: HA for MySQL and MariaDB - Comparing Master-Master Replication to Galera ClusterMariaDB Replication 主要透過 Binary Log 以及 Relay Log 的方式進行同步。  Master 會將 CREATE、 ALTER、 INSERT、 UPDATE 還有 DELETE  這些操作的步驟記錄在 BInary Log 裡面。  Slave 會定期 Polling Master Binary Log (使用 MySQL API, 這間隔趨近 Real-Time)，並將 Binary Log 資訊以及同步紀錄寫在自己的 Relay Log 裡面。  Slave 最後根據 Relay Log 資訊來套用 SQL 到 Slave MariaDB 上。  完成同步。設定步驟此文章採用版本資訊如下:  MariaDB 10.3.32  Ubuntu 20.04 LTS環境:  Master MariaDB 192.168.89.131  Slave MariaDB 192.168.89.132  以下步驟開始在 Master MariaDB 上操作  設定 my.cnf 檔，啟用 Binary Log    mkdir /root/configtouch /root/config/my.cnf        my.cnf (在 Master-Slave Replication Cluster 裡，每台 MariaDB server_id 需要不一樣)     [mariadb] log-bin server_id=1 log-basename=master1 binlog-format=mixed        部署 Master MariaDB     export IP=192.168.89.131 docker run --name mariadb-master -p $IP:3306:3306 -v /root/config:/etc/mysql/conf.d -e MARIADB_ROOT_PASSWORD=123456 -d mariadb:10.3.32              此指令為測試用，若是在 Production，請記得設定加上 Persistent Data 存放目錄以及相關帳號設定，不要使用 Root。        建立 Replication 用的帳號     docker exec -it mariadb-master bash $ mysql -u root -p123456         MariaDB [(none)]&amp;gt; GRANT REPLICATION SLAVE ON *.* to replicator@&#39;%&#39; IDENTIFIED BY &#39;secret&#39;; MariaDB [(none)]&amp;gt; FLUSH PRIVILEGES; MariaDB [(none)]&amp;gt; FLUSH TABLES WITH READ LOCK;        查看 Master 資訊，需記下 Binary Log 名稱    MariaDB [(none)]&amp;gt; SHOW MASTER STATUS;+ — — — — — — — — — + — — — — — + — — — — — — — + — — — — — — — — — +| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+ — — — — — — — — — + — — — — — + — — — — — — — + — — — — — — — — — +| master1-bin.000003 | 466 | | |+ — — — — — — — — — + — — — — — + — — — — — — — + — — — — — — — — — +1 row in set (0.00 sec)              以下步驟開始在 Slave MariaDB 上操作        設定 my.cnf 檔，啟用 Binary Log     mkdir /root/config touch /root/config/my.cnf        my.cnf (在 Master-Slave Replication Cluster 裡，每台 MariaDB server_id 需要不一樣)     [mariadb] server_id=2        部署 Slave  MariaDB 。     export IP=&amp;lt;slave node IP&amp;gt; docker run --name mariadb-slave -p $IP:3306:3306 -v /root/config:/etc/mysql/conf.d -e MARIADB_ROOT_PASSWORD=123456 -d mariadb:10.3.32              此指令為測試用，若是在 Production，請記得設定加上 Persistent Data 存放目錄以及相關帳號設定，不要使用 Root。        設定連到 Master MariaDB，並啟用 Slave 服務， CHANGE MASTER 根據 Master 資訊填寫。     docker exec -it mariadb-slave bash $ mysql -u root -p123456         MariaDB [(none)]&amp;gt; CHANGE MASTER TO MASTER_HOST=&#39;192.168.89.131&#39;, MASTER_USER=&#39;replicator&#39;, MASTER_PASSWORD=&#39;secret&#39;, MASTER_LOG_FILE=&#39;master1-bin.000003&#39;, MASTER_LOG_POS=466; MariaDB [(none)]&amp;gt; START SLAVE;              MASTER_LOG_FILE 代表要去讀 Master 的 Binary Log 名稱MASTER_LOG_POS 代表要從 Binary Log 哪一個位置開始同步，需跟 SHOW MASTER STATUS; 的 Position  值一樣。        查看 Slave 資訊 (需確認 Slave_IO_Running 以及 Slave_SQL_Running 是否為 Yes)     MariaDB [(none)]&amp;gt; SHOW SLAVE STATUS;              以下步驟開始在 Master MariaDB 上操作        UNLOCK Master MariaDB Table。    MariaDB [(none)]&amp;gt; UNLOCK TABLE ;        這樣就完成，可以嘗試看看透過 Master 進行寫入動作，Slave 那邊是否會同步。    MariaDB [(none)]&amp;gt; CREATE DATABASE hello;MariaDB [(none)]&amp;gt; USE hello;MariaDB [hello]&amp;gt;  CREATE TABLE hellotable (`id` int, `name` varchar(10) ) ;MariaDB [hello]&amp;gt; INSERT INTO hellotable (`id`,`name`) VALUES (&#39;1&#39;,&#39;pohsien&#39;) ;MariaDB [hello]&amp;gt; SELECT * FROM hellotable;+------+---------+| id   | name    |+------+---------+|    1 | pohsien |+------+---------+1 row in set (0.000 sec)              以下步驟開始在 Slave MariaDB 上操作        在 Slave 可以馬上看到剛剛在 Master 建立的 DB、Table 以及 Record。    MariaDB [(none)]&amp;gt; USE hello;MariaDB [hello]&amp;gt; SELECT * FROM hellotable;+------+---------+| id   | name    |+------+---------+|    1 | pohsien |+------+---------+1 row in set (0.000 sec)        後續可以搭配 HA Proxy 以及程式端設定讀寫分離，讓程式寫入資料時到 Master 上去寫，要讀的時候，就透過 HA Proxy Load Balancing 到任一台 Slave 去讀，可以提高效率以及增加高可用性。  💡 請注意，在 Master-Slave Replication 中同步是單向的，也就是只能 Master 同步給 Slave，並不能 Slave 同步給 Master，如果不小心在 Slave 寫入資料，會造成 split-brain 的嚴重情況，Cluster 同步會出問題。Auto-FailoverMariaDB Master-Slave Replication 預設不支援動態 Failover，如果遇到  Master 故障，需要手動進行切換，將 Slave 啟用 binlog，讓他變成 Master，然後剩下的 Slave 必須設定 CHANGE MASTER 來將他指到新的 Master，皆需要管理者手動設定。另外在 Load Balancer 端，像 HA Proxy 這類型的 Load Balancer，也很難自動根據 MariaDB Master 或 Slave 角色變換調整 Server Pool，步驟相當繁瑣。因此 MariaDB 官方釋出一個工具 MaxScale，他裡面包含了許多模組，例如 Monitor 模組，可以監看 MariaDB Cluster 狀態，並實現 auto-failover 以及 auto-rejoin (掛掉的 Node 恢復後主動加回 Cluster)。 Service 模組，可以實現路由，將流量導到正確身份的 MariaDB 身上，當有 Failover 發生後，也可以自動轉換流量導向，非常方便。MaxScale 設定步驟  此文章採用版本資訊如下:      MariaDB 10.3.32    Ubuntu 20.04 LTS    MaxScale 6.2.1  環境(總共有四台 VM):  Master MariaDB 192.168.89.131 (server_id: 1)  Slave MariaDB-1 192.168.89.132 (server_id: 2)  Slave MariaDB-2 192.168.89.133 (server_id: 3)  MaxScale 192.168.89.134  參考 MariaDB MaxScale Installation Guide 安裝 MaxScale 以及設定完 MariaDB Master-Slave Cluster。  在 MaxScale VM 編輯 MaxScale 設定檔    $ vim /etc/maxscale.cnf        建立三台 MariaDB 資訊， [] 名稱可以任意取名，這邊設定很像設定 Load Balancer 的 Server Pool (Backend) 一樣。     ... [server1] type=server address=192.168.89.131 port=3306 protocol=MariaDBBackend [server2] type=server address=192.168.89.132 port=3306 protocol=MariaDBBackend [server3] type=server address=192.168.89.133 port=3306 protocol=MariaDBBackend ...        設定 Monitor，監控 MariaDB 的狀態，其中這裡也可以設定 auto_failover 以及 auto_rejoin 來實現 Master 身份自動轉移以及自動將排除異常的 Node 重新加回 Cluster。    ...[MariaDB-Monitor]type=monitormodule=mariadbmonservers=server1,server2,server3user=rootpassword=123456monitor_interval=2000# 啟用自動 Failoverauto_failover=true# 啟用自動 rejoinauto_rejoin=true...            設定 Service (路由)，預設是讀寫分開，這邊可以設定 Listener 以及 Backend，可以將讀寫切分成不同的 Listener，並對應到不同的 Backend。    在此我們將 Write 的動作都導向到 Master MariaDB 身上，Read 的動作則導向到 Slave MariaDB 身上，MaxScale 會自己判斷身份，所以只要將全部 MariaDB 都加進 Service 就好。          若要讀寫分開也必須看自己的 Application 是否有支援這樣設計         ... #--------- Services (LoadBalancr 後端的 Server Pool) ---------- ## 給 Reqd-Only 使用 [Read-Only-Service] type=service router=readconnroute # 這邊設定要當作 Backend 的 Server servers=server1,server2,server3 user=maxscale password=123456 # 設定要作為 Backend 的種類，這裡表示會從 servers Group 裡面挑出 Slave 來做 LoadBalancing router_options=slave ## 給 Read-Write 使用  [Read-Write-Service] type=service router=readconnroute # 這邊設定要當作 Backend 的 Server servers=server1,server2,server3 user=maxscale password=123456 # 設定要作為 Backend 的種類，這裡表示會從 servers Group 裡面挑出 Master 來做 LoadBalancing router_options=master #----------- Listeners (LoadBalancr 前端的窗口) -------------- [Read-Only-Listener] type=listener service=Read-Only-Service protocol=MariaDBClient address=192.168.89.134 port=4008 [Read-Write-Listener] type=listener service=Read-Write-Service protocol=MariaDBClient port=4006 address=192.168.89.134 ...              💡 這邊的 user password 是給 MaxScale 使用的，因為 MaxScale 主要接收 Client 連線的窗口，所以他會需要權限能夠讀 MariaDB 的 User 資訊以及連到 MariaDB 去做一些操作，例如修改 Master-Slave 設定，可查看 Creating a user account for MaxScale 。        完成後重啟 MaxScale，這樣設定完之後，連線資訊如下:          Read 使用的連線資訊:  192.168.89.134:4008      Write 使用的連線資訊: 192.168.89.134.4006         $ systemctl restart maxscale.service        在 MaxScale VM 查看 Monitor 資訊，如果把 Master 關機，可以看到 State 切換，也可以參考 Manual Failover 手動切換角色 maxctrl call command mariadbmon failover Monitor 。    $ maxctrl list servers┌─────────┬────────────────┬──────┬─────────────┬─────────────────┬──────────┐│ Server  │ Address        │ Port │ Connections │ State           │ GTID     │├─────────┼────────────────┼──────┼─────────────┼─────────────────┼──────────┤│ server1 │ 192.168.89.131 │ 3306 │ 0           │ Master, Running │ 0-3-7224 │├─────────┼────────────────┼──────┼─────────────┼─────────────────┼──────────┤│ server2 │ 192.168.89.132 │ 3306 │ 0           │ Slave, Running  │ 0-3-7224 │├─────────┼────────────────┼──────┼─────────────┼─────────────────┼──────────┤│ server3 │ 192.168.89.133 │ 3306 │ 0           │ Slave, Running  │ 0-3-7224 │└─────────┴────────────────┴──────┴─────────────┴─────────────────┴──────────┘        透過 MaxScale 存取 MariaDB 測試 LoadBalancing 是否正確。    $ msql -h 192.168.89.134 -P 4006 -u myuser -p$ msql -h 192.168.89.134 -P 4008 -u myuser -p              💡 這邊的使用者是給 application 連線用的，這個需要注意，因為連線方式是: client → maxscale  → mariadb ，所以需要設定這個使用者能從 client 端以及 maxscale 連到 MariaDB，可參考 Creating client user accounts        若透過 4006 port 成功連到 MariaDB，查看連到的 DB Server id，應該不管在哪裡連都會是 Master 那台 Node。    MariaDB [(none)]&amp;gt; SELECT @@server_id ;+-------------+| @@server_id |+-------------+|           1 |+-------------+        若透過 4008 port 成功連到 MariaDB，查看連到的 DB Server id，應該會是任一台 Slave 。    MariaDB [(none)]&amp;gt; SELECT @@server_id ;+-------------+| @@server_id |+-------------+|           3 |+-------------+      MaxScale with Keepalived由於 MaxScale 會不斷偵測 MariaDB 異常以及提供 Load Balancing，如果 MaxScale 本身異常的話，會導致這些機制停掉，因此在 Production 環境 通常需要多台來達到 HA。MariaDB 官方採用 Keepalived 來實現 MaxScale HA，可以參考 MaxScale HA setup using Keepalived and MaxCtrl 。圖片來源: MaxScale HA setup using Keepalived and MaxCtrl參考資料Introduction  HA for MySQL and MariaDB - Comparing Master-Master Replication to Galera Cluster  Replication OverviewSetup Replication  Setting Up Replication  MariaDB Load Balancing with HAProxy on Centos 7  MariaDB Replication: 2 Easy Methods  How to Configure MariaDB Master-Master/Slave Replication?MaxScale  MariaDB MaxScale  MariaDB MaxScale Installation Guide  Automatic Failover With MariaDB Monitor  Connection Routing with MariaDB MaxScale  Setting up MariaDB MaxScale  MariaDB MaxScale Configuration Guide  MariaDB Load Balancing with HAProxy on Centos 7  MaxScale HA setup using Keepalived and MaxCtrl  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "2021 個人年度回顧",
    "url": "/blog/2021-review/",
    "categories": "Others",
    "tags": "Personal",
    "date": "2021-12-31 22:02:55 +0800",
    





    "snippet": "不知不覺一年又過了，又到了年底回顧及審思的時間。2021 算是個人比較混亂的一年，不管是工作還是個人上，覺得今年整體都蠻混亂，工作上的問題比較多，導致沒辦法切割拿捏生活跟工作，所以今年都比較封閉一點，連部落格都停擺。不過還好到年底慢慢穩定下來，且有機會好好休息，能夠停下腳步好好審視今年，並為 2022 做準備。不過不管如何，2021 年都順利結束，明年繼續加油。2021 回顧休閒及其他  年初因為一些私人事情陷入了完全低潮，很謝謝周遭朋友鼓勵跟打氣，才能快速振作。  持續參加健身課，重訓 + TRX + 有氧，不過後來中間疫情中斷，有點復胖回來。  買了專業證照課，準備了一兩個月，完全沒時間考，浪費了考試卷的錢，明年要繼續努力考到！  今年在社群上比較沒有特別精力參與，希望自己能整頓一下，然後好好回歸協助夥伴相關事務！工作方面  成功帶完 6 個實習生(一年)，還收到了學生的感謝卡跟禮物，一個窩心。  今年底開始帶新的實習生，跟實習生一起討論交流技術，每次帶實習生都覺得自己好像也回到學生時期。  工作職務各種變動，面臨新的挑戰，雖然剛好藉此機會跟各種不同專業的人合作，但也因為變動關係，心態上很混亂，一直不斷再調整。  完成了幾個案子，雖然都很驚險，但還好都順利結束，且其中一個應該是目前碰過比較複雜的案子，雖然過程非常痛苦，但除了提升專業及獲得經驗以外，也達成了成就。  工作上同樣是協助 Cloud Native 相關事務，比起去年參與了更多困難的專案跟事務，因此今年透過工作，增加蠻多實戰經驗跟專業知識，感覺跟去年比進步許多，仍須繼續努力。  拍了人生第一隻 MV，還擔任一日鼓手 xD。  第一次到攝影棚錄製教育訓練，很新鮮。  第一次參與了公司記者會，雖然是當工作人員，但是還是見識到很大的陣仗。2022 展望  加強專業技術以及英文能力，嘗試更多挑戰與機會。  更新停擺已久的部落格，強迫自己多撰寫文章。  養成閱讀習慣，強迫自己學習。  嘗試平衡工作跟生活， 加強時間管理跟分配，留給更多的時間做自己想做的事以及休閒。  持續維持運動跟控制飲食，希望能提升肌肉量，然後嘗試更多種運動跟活動。  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "2020 個人年度回顧",
    "url": "/blog/2020-review/",
    "categories": "Others",
    "tags": "Personal",
    "date": "2020-12-31 16:25:20 +0800",
    





    "snippet": "2020 回顧2020 年真的是讓人印象深刻的一年，因為新冠肺炎影響關係，許多計畫都被影響，但就整體上來看，今年對我個人來說仍然算是一個蠻有收穫的一年，做了許多嘗試以及達各種成就。工作方面今年初換了新公司，算是一個新的開始，雖然忙到炸裂，進去還沒過試用期，就忙到好像過了好幾年一樣，但卻是忙得有意義，非常充實。  新公司: 換了新公司，一個新的開始。  Work From Home 初體驗: 由於部門較彈性加上疫情關係，因此可以在家上班，算是一個新的體驗，不過雖然 Work From Home 很自由，但是也有相對的缺點，例如同事溝通討論困難、沒有下班的感覺或邊緣化 QQ 之類的。  帶實習生: 一次帶了 8 個實習生(大學生)，雖然工作量增加了，但是跟這群年輕大學生一起 co-work 也為工作氛圍帶來了幾分樂趣。  半夜系統升版: 第一次體驗半夜到客戶那邊升 Patch，跟客戶徹夜長談(?)，然後一同奮戰救系統到早上。  協助公司各種大大小小的教育訓練，訓練資料整理、口條跟台風的好機會。  專業部分: 目前在公司還是負責 Kubernetes 相關業務，各種研究 Kubernetes，感覺比去年還更加熟悉相關運作，但仍需要繼續學習精進。  成功獲得 Red Hat EX280 OpenShift 證照。社群方面 (Cloud Native Taiwan User Group)今年算是比較完整的參與了一整年的社群活動，從每個月的 Meetup、擺攤、COSCUP 到年末晚會，各種完整參與。  第一次擔任 COSCUP CNTUG 社群負責人: 擔任 COISCUP 2020 CNTUG 社群負責人，負責接洽跟處理一些 COSCUP 事務。這部分真的蠻辛苦的，加上又卡到很多其他事情，不過還好有 Phil Huang 小飛機 以及其他社群夥伴協助，不然我可能直接死去。  第一次參與年末晚會: 第一次以工作人員身份協同舉辦了社群年末晚會，雖然這部分我比較沒幫上什麼忙，但是社群能夠順利舉辦年末晚會，有一種 2020 Happy Ending 的感覺。  Meetup Talk (GitOps: Flux Introduction): 今年只有在年初時，講了一場 Meetup Talk，後面就因為換公司，各種熟悉跟處理公司事，比較沒什麼時間研究跟分享。  協助擺攤: 今年同樣協助了社群在 Kubernetes Summit 擺攤，認識了不少人以及交換了許多貼紙。  SRE 讀書會: 今年有幸參與 SRE 讀書會，雖然有時候太忙進度落後，但是每次參與都學習到許多寶貴的維運經驗。休閒及其他今年體驗各種新活動，達成許多人生成就。  攀岩(抱石) 首次突破 LV2 等級 xD。  取得人生中第一張水肺潛水證照，潛水菜鳥一枚。  買了人生中第一台攝影機 (DJI Osmo Ppocket)，vlog 錄起來！  年底參與台南野餐，認識許多台南的朋友，大家一起ㄎㄧㄤ xD  報名了健身房團課(TRX 及各種有氧)，初體驗。  把空拍機弄到炸機，掉到山裡消失。  成功完成 VoiceTube Hero 半年零元挑戰，還推坑許多人去參加。  買了人生中第一台 MacBook Pro，希望可以戰 10 年。  成功將家裡改造成辦公環境，筆電 + 雙螢幕 + 螢幕架 + 人體工學椅。2021 展望  增強專業能力部分，提升各方面不足點。  多撰寫文章，記錄生活瑣事跟專業筆記。  多出來 Conference 或是 Meetup 分享，提升能見度及擴展更多人脈。  多貢獻開源專案，練習參與進去。  增強英文能力，讓口說能再更順一點。  嘗試各種新的活動，達成更多人生成就。  持續維持運動跟控制飲食。結語由於今年換工作關係，整體變得很忙碌，時間一下就過了，每天都過得很充實，工作部分自己認為也表現得還不錯，各方面都成長不少，也在工作上認識許多貴人。比較需要改進的地方是，花太多時間在工作上，導致還有更多想做的事都沒辦法做，希望明年能夠再加強時間管理，並同時兼顧事業及生活。今年很幸運結識許多重要的朋友及貴人，我覺得對於我人生及生活態度有蠻大的影響，這應該是今年最大的收穫。最後，2020 年順利結束，明年繼續加油。  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "2020 VoiceTube Hero 零元挑戰心得",
    "url": "/blog/2020-voicetube-hero/",
    "categories": "Others",
    "tags": "Personal",
    "date": "2020-08-11 00:00:00 +0800",
    





    "snippet": "今年二月的時候，想說加強英文，報名了 VoiceTube Hero 挑戰，然後還直接報名當時第八屆最長的 6 個月 90 堂課挑戰。然後因為怕沒動力所以抓了其他朋友一起挑戰，還創個群組大家每天互相提醒要上課。這個挑戰主要是在期限內(6個月內)，符合以下條件，就可以全額退費：  上完 90 堂課  每堂課複習 2 次，也就是半年要上 90 * 3 = 270 次  每週至少要上 12 堂課，只要一週失敗，直接挑戰失敗一堂課會提供影片，影片看完之後，做選擇題/克漏字/文法/口說/單字測驗，平均一堂課約 30-40 分鐘左右，有時候遇到很難的會更久。VoiceTube 有提供 Web 跟 App，所以可以根據自己方便決定要使用哪一個平台上課。一開始想說一天 2 堂課還好，每天花個 1~2 小時上，強迫自己學習，但是有時候當週很忙就會非常累，例如加班到晚上回家還要補上英文，或是可能當週出遊還要擔心英文沒上完，然後在飯店用手機上課。所以到最後蠻長變成積到六日在做，雖然這樣不太好 xD這半年剛好卡到社群活動非常忙，整個時間卡在一起，雖然痛苦，不過剛好趁這機會強迫自己練英文，終於在 08/09 通過挑戰，結束這半年的挑戰。心得整體來說挑戰不錯，課程規劃跟系統也感覺得出很用心，課程也都是採用很有意義的影片，例如：碳交易、介紹國家旅遊、股票介紹或是一些冷知識，除了學英文也學到許多知識，可惜的是課程主要是訓練單字跟聽力居多，針對寫作或是其他文法部分比較薄弱一點(最近有新版本的系統，不知道會不會不一樣)，不過其他部分都還做得不錯，很用心，而且上完課之後，還會把筆記、課程資料、單字本、文法本都完整打包好給你下載，讓你之後課程結束後都可以複習，很貼心。當初參加挑戰主要是強迫自己讀一下英文，不過在很忙的時候真的會蠻辛苦的，會擔心英文上不完，所以就變成不管再累都要在禮拜日 23:59 分以前做完 12 堂課，這也意識到時間規劃的重要性！如果讀者有興趣也可以挑戰看看，可以試做看看官網的題目，挑戰完之後除了能加強英文還能退費，蠻不錯的！最後，雖然通過了挑戰，但覺得自己英文能力還需要再加強，還不太夠，繼續持續學習，另外謝謝一起挑戰的戰友，這陣子的互相勸退，還好最後大家都一起通過挑戰！  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "End-to-End Testing for Kubernetes (Part II) - Conformance Testing",
    "url": "/blog/e2e-testing-for-kubernetes-part-ii/",
    "categories": "Kubernetes",
    "tags": "kubernetes, testing",
    "date": "2019-10-27 04:17:14 +0800",
    





    "snippet": "此系列文為 E2E Testing for Kubernetes 的介紹，如尚未看過前一篇文章，可以參考底下連結:  End-to-End Testing for Kubernetes (Part I) - kubetest  End-to-End Testing for Kubernetes (Part II) - Conformance TestingConformance Testing在前一篇文章裡，我們介紹到如何使用 kubetest 執行 Kubernetes E2E Test ， kubetest 會使用 Kubernetes Binary 開啟新的乾淨 Cluster 去做測試。在這一篇文章裡我們會介紹如何對自己部署的 Cluster 做 E2E Test。Conformance Testing ，一致性測試，這個測試是 E2E Testing 底下的一個子集合，其主要是驗證 Kubernetes 核心的功能或是 GA 版本的 API ，也就是不管任何版本的 Cluster 都應該要能使用的基本功能。這個測試也可以解讀成: 「不管任何版本或平台的 Cluster 在經過 Conformance Test 之後的結果都要是一致的」。由於 Conformance Test 比較不限定於 Cluster 版本或是平台，因此可以用來測試自己部署的 Cluster 是否是正常的。另外 Conformance Test 也是非破壞性的測試，不會包含 [Disruptive] 的測項，因此並不會影響到 Cluster 上面運行的其他服務。  在前一篇文章有提到 Kind of Test ，其中一個 Label 是 [Conformance] ，這個就是代表 Conformance Test 的測項。Conformance Test RequirementsKubernetes 有列出 Conformance Test 需要滿足的條件，有非常多項，其中包含只測試 GA 版本的 API 、必須可以使用在任何 Provider 上、不需要連接到 Public Network 、不需要 Privileged 權限或是不能包含具有關於 Node 或是平台相依性的測試，如硬體規格限制等等。不過這份文件也有提到如果將來有足夠的測項能測試 Cluster 之後，會慢慢的放寬這些條件，加入更多的測項進來。  it tests only GA, non-optional features or APIs (e.g., no alpha or beta endpoints, no feature flags required, no deprecated features)  it does not require direct access to kubelet’s API to pass (nor does it require indirect access via the API server node proxy endpoint); it MAY use the kubelet API for debugging purposes upon failure  it works for all providers (e.g., no SkipIfProviderIs/SkipUnlessProviderIs calls)  it is non-privileged (e.g., does not require root on nodes, access to raw network interfaces, or Cluster admin permissions)  it works without access to the public internet (short of whatever is required to pre-pull images for conformance tests)…如果想了解更細部的需求條件可以參考 Conformance Test Requirements。Exexcution我們同樣可以使用 kubetest 來執行 Conformance Test ，執行步驟非常簡單，只需要限定只執行 [Conformance] Label 的測項即可。  前置作業# Checking your kubernetes server version$ kubectl get versionServer Version: version.Info{Major:&quot;1&quot;, Minor:&quot;15&quot;, GitVersion:&quot;v1.15.3&quot;, GitCommit:&quot;2d3c76f9091b6bec110a5e63777c332469e0cba2&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-08-19T11:05:50Z&quot;, GoVersion:&quot;go1.12.9&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}# Change Kubernetes repository to the specific version$ cd $GOPATH/src/k8s.io/kubernetes$ git checkout v1.15.3# Build e2e.test, ginkgo and kubectl# 這邊也可以直接使用　kubetest --build ，只是 Conformance Testing 不需要 # build 這麼多東西。$ make WHAT=&quot;test/e2e/e2e.test vendor/github.com/onsi/ginkgo/ginkgo cmd/kubectl&quot;這邊需要注意的是: kubetest 會直接抓 Kubernetes 目錄 Build 出來的 kubectl 當作 Client 去做測試， 如果 kubectl 的版本 ( GitVersion ) 與 Server 版本不一致， kubetest 會報錯，因此最好先將 Kubernetes 切換到對應版本的 branch/tag ，再 build e2e.test 跟 kubectl 比較好。如果真的想要用不同版本的 Client (kubectl) 做測試，可以在 kubetest 後面加上 --check-version-skew=false flag，但是不建議這樣做，因為可能會影響測試的準確度。2.執行測試# Setup for conformance tests$ export KUBECONFIG=/path/to/kubeconfig$ export KUBERNETES_CONFORMANCE_TEST=y# Run testing$ kubetest --provider=skeleton --test --test_args=&quot;--ginkgo.focus=\\[Conformance\\]&quot;# Run testing with different version of client$ kubetest --provider=skeleton --test --test_args=&quot;--ginkgo.focus=\\[Conformance\\]&quot; --check-version-skew=false當設定 KUBERNETES_CONFORMANCE_TEST=y 時， kubernetes/hack/ginkgo-e2e.sh 就會從 KUBECONFIG 來取得 Master 位置，因此不再需要使用 --deployment flag 去告訴 kubetest (Ginkgo) Cluster 資訊。--provider=skeleton: 這邊的 skeleton 筆者也不確定如何解釋，類似於只有骨架，表示你的 Cluster 只有提供 API 介面(直接提供kubeconfig就可以存取到 Cluster )，而看不到整個整體的 Cluster ，這邊如果讀者有更好的解釋的話，再麻煩幫我修正一下，謝謝。  筆者實際執行 Conformance Test 大概花了 3~4 小時左右，不過同樣可能跟筆者 Homelab 硬體資源有關，實際上應該不需要這多時間。Test Lists由於 Conformance Testing 是 E2E Testing 的子集合，因此其測項一樣位於 kubernetes/test/e2e/ 裡，不過 Kubernetes 有特別將 Conformance Testing 的測試項目清單記錄在 conformance.txt 底下，如果要細看每一個測項內容的話也可以參考 Kubernetes Conformance Test Suite - v1.9。kubernetes/test/conformance/testdata/conformance.txt查看其中一個 spec ，會發現 Conformance Test 是使用 framework.ConformanceIt() ，而不是像 E2E Test 使用 Ginkgo.It() 。kubernetes/test/e2e/common/pods.go   ...   /*      Release : v1.9      Testname: Pods, assigned hostip      Description: Create a Pod. Pod status MUST return successfully and contains a valid IP address.   */   framework.ConformanceIt(&quot;should get a host IP [NodeConformance]&quot;, func() {      name := &quot;pod-hostip-&quot; + string(uuid.NewUUID())      testHostIP(podClient, &amp;amp;v1.Pod{         ObjectMeta: metav1.ObjectMeta{            Name: name,         },         Spec: v1.PodSpec{            Containers: []v1.Container{               {                  Name:  &quot;test&quot;,                  Image: imageutils.GetPauseImageName(),               },            },         },      })   })   ...實際去看 framework.ConformanceIt()  內容 (位於 kubernetes/test/e2e/framework/framework.go) ，會發現 ConformanceIt() 的功能為貼 [Conformance] Label ，至於為什麼要特別額外用一個 function 來貼 Label ，這邊官方註解是方便靜態分析用，不過筆者認為這樣也可以方便之後針對 Conformance Test 作修改，例如對所有的 Conformance Test 加上額外的 Label 或是增加什麼內容，直接透過 ConformanceIt() 就可以統一修改了。kubernetes/test/e2e/framework/framework.go   ...   // ConformanceIt is wrapper function for ginkgo It.  Adds &quot;[Conformance]&quot; tag and makes static analysis easier.   func ConformanceIt(text string, body interface{}, timeout ...float64) bool {      return ginkgo.It(text+&quot; [Conformance]&quot;, body, timeout...)   }   ...Write Your Own Test接下來介紹如何撰寫自己的測項 ，基本上都跟 E2E Test 差不多，不過不確定是不是因為一般使用者比較常使用到 Conformance Test ， 這部分文件比 E2E Test 完整許多。我們將撰寫測試分成三個步驟：  撰寫測試。  確保你的測試有符合 [Conformance Test Requirements](#Conformance-Test-Requirements）。  發送 PR 。細部流程可參考 Promoting Tests to Conformance 。1. 撰寫測試在撰寫 Conformance Test 時必須遵守兩個的格式，一個是一定要使用 framework.ConformanceIt() ，不要使用 Ginkgo.It 。 另一個是一定要撰寫 metadata ，格式如下：/*  Release : v1.15.3  Testname: Kubelet: log output  Description: By default the stdout and stderr from the process being  executed in a pod MUST be sent to the pod&#39;s logs.*/framework.ConformanceIt(&quot;it should print the output to logs&quot;, func() {  ...})測試放置位置以及 Import 位置都與我們之前撰寫的 E2E Test 相同，因此這邊只簡單列出流程，細節部分可以參考前一篇文章。1. 在 kubernets/test/e2e 建立資料夾來放置你的測試檔。2. 在 kubernets/test/e2e/e2e_test.go 以及 kubernets/test/e2e/BUILD import 你的測試。3. 在 kubernets/test/e2e/&amp;lt;yourfolder&amp;gt;/ 下新增你的 BUILD 檔。4. 更新 conformance.txt5. 使用 kubetest --build 重新 build e2e.test比較需要注意是第四步必須執行以下指令來更新 conformance.txt :$ go run test/conformance/walk.go test/e2e &amp;gt; test/conformance/testdata/conformance.txt  請記得在撰寫自己的測試時一定要加上對應 Label ，如 [Slow] 、 [Serial] 、 [Disruptive] 等等，這樣可以讓測試人員更加了解你的測項的特性，如果不確定要加上哪些 Label 可以在 slack 或是 發佈 Issue / PR 時，標註 #kinds-of-tests  來詢問。2. 確保你的測試有符合 [Conformance Test Requirements]這部分可以參考 Conformance Test Requirements。3. 發送 PR1. PR Title:  &quot;Promote xxx e2e test to Conformance&quot;2. 撰寫測項的資訊以及 metadata，並加上 PR Label 以及標註負責的 SIG。     - /area conformance     - @kubernetes/sig-architecture-pr-reviews @kubernetes/sig-xxx-pr-reviews        @kubernetes/cncf-conformance-wg    - Any necessary information (e.g.  例如解釋為什麼測項無法在 Windows 執行)3. 將 PR 加到 SIG Architecture&#39;s Conformance Test Review board 的 To Triage 欄位。4. 使用 /test pull-kubernetes-e2e-aks-engine-azure-windows 來測試項目能否正常跑在 Windows Node 上  Conformance Test Review boardFor WindowsComforance Testing 並沒有強制要求測項一定要支援 Windows Node ，但是既然 Kubernetes 有支援 Windows ，那還是必須要能夠對 Windows Node 做 Conformance Test 。在現有的測項中，大部分的測項都是可以在 Windows Node 執行的，只有少部分貼上 [LinuxOnly] 的測項是不能跑在 Windows 上的。在撰寫自己的測試時，如果不確定 Linux Node 和 Windows Node 在測試執行上的差異或是不確定你寫的測項是否可以運行在 Windows 的話，可以參考 Windows &amp;amp; Linux Considerations 。如果撰寫的測試不支援 Windows ，一定要標註 [LinuxOnly] Label，且在送PR時寫清楚為何不能跑在 Windows Node 上，讓 Reviewer 知道。VMware Tanzu (Heptio) Sonobuoy另外一個常見的 Kubernetes Conformance Testing Tool 是由 VMware Tanzu (Heptio) 開發的 Sonobuoy 。 Sonobuoy 提供比 kubetest 更方便的介面來做 Conformance Test ，只需要簡單幾行指令就可以執行測試，測試項目也與 kubetest 使用的 ( kubernetes/test/e2e/... ) 是完全一樣的，差別在於 Sonobuoy 是預先將測項全部放到 Docker Image 裡面，因此不需要像 kubetest 需要特別 Build e2e.test，不過需要注意的是 Sonobuoy 只支援前三新的 Kubernetes 版本。Sonobuoy WebsiteCertified KubernetesSonobuoy 同時也是 CNCF 官方用來認證 Kubernetes Cluster 的 Conformance Testing Tool，企業可以使用 Sonobuoy 來驗證自己開發的 Kubernetes 部署工具佈出來的 Cluster ，如果通過測試可以將結果提交到 GitHub ，該部署工具就可以獲得 CNCF 的認證標章，並顯示在 CNCF 官網上，詳細驗證流程可以參考 Certified Kubernetes 。ExecutionSonobuoy 執行方式也很簡單，只需要設定 KUBECONFIG 然後執行 sonobuoy run 就可以跑 Conformance Test 了。$ export KUBECONFIG=/path/to/kubeconfig$ go get -u -v github.com/heptio/sonobuoy# Start testing and wait until they are finished run:$ sonobuoy run --wait# Get the result$ results=$(sonobuoy retrieve)$ sonobuoy e2e $results# Delete the objects deployed by sonobuoy$ sonobuoy deleteResultSonobuoy 執行結果報告大致架構如下( Sonobuoy Snapshot Layout )：servergroups.json: 紀錄 Kubernetes API 資訊serverversion.json: 紀錄 Kubernetes Cluster 版本資訊hosts放置每個 Node 的 Configuration ( configz.json )跟健康狀態 ( healthz.json )meta  config.json: 放置 Sonobuoy 的設定檔。  query-time.json: Sonobuoy 在處理各種 Resource 的反應時間，類似 Performenace Testing 。  run.log: Sonobuoy執行的 log ，注意這不是 Kubernetes Log。plugins放置 Plugins 的詳細資訊。podlogs放置 Pod 的 Log ，注意這裡預設只會有 Sonobuoy 產生的 Pod 的 Log。resources放置 Kubernetes Cluster 的 Resource 資訊。Cluster: 放所有不屬於任何 Namespaces 的 Resources，如 RoleBinding 、 Namespaces 等等。ns: 放各個不同 Namespaces 的 Resources。這邊是依照 Resource 種類去作分類，一個種類就是一個 JSON 檔，例如 pohsien namespace 裡面有100個 Pod ， Sonobuoy 就會在 resources/ns/pohsien/pods.json 放100個 Pod 資訊，並不會有100個 JSON 檔。Sonobuoy vs kubetestSonobuoy 提供了比 kubetest 更加簡單的方式執行 Conformance Test，其不需要 Build Kubernetes Binary ，也不需要比較麻煩的步驟執行測試。輸出結果部分，Sonobuoy 也提供很完善的 Output 機制，方便測試人員去查看測試結果。因為上述的優點，所以 Sonobuoy 成為了目前主流的 Kubernetes Conformance Testing Tool 。但是由於 Sonobuoy 畢竟是第三方的工具，它會從 Kubernetes 官方目錄取得測項以及需要的資料並放置在 Sonobuoy Docker Image ，這提升了使用上方便性，但也導致其可能會沒辦法取得最新的測試項目。主要因為 Kubernetes 更新速度非常快，在每一次的更新之後， Sonobuoy 都會需要去更新 Image，而在等待 Sonobuoy 更新這段時間測項就會出現落差。不過筆者認為如果沒有要測試最新版本的 Cluster ，就比較不需要擔心這個問題，或著是可以設定排程一段時間更新 Sonobuoy ，然後再次做測試。Summary在這系列文我們介紹了 Kubernets End to End Testing ，包括怎使用 kubetest 執行 E2E Test 以及 Conformance Test ，也簡單介紹了如何撰寫自己的測項，最後也介紹如何使用 CNCF 官方的 Comformance Testing Tool - Sonobuoy 。E2E Testing 是在企業導入 Kubernetes 流程中是相當重要的一步，無論是使用什麼工具部署，建議都使用 E2E Testing 來驗證 Cluster 是否正常，這樣當發生任何問題時，比較可以排除掉 Cluster 本身的問題，減少問題定位的成本。另外也可以定期的執行 E2E Testing / Conformance Testing 或是直接將測試整合進 CI/CD 流程裡，不過最好根據自己的環境狀況來評估，雖然 Conformance Testing 是無破壞性的測試，但是直接對於 Production 環境去做測試其實還是會有一些風險 (例如影響效能或是非預期內錯誤等等) ，因此還是需要特別注意，或著是也可以在測試前，先將重要服務轉移出去，待測試完成後再轉移回來，也是一個方法，實際執行方式可以根據自己的環境去做評估。References  Conformance Testing in Kubernetes  Kubernetes Conformance Test Suite - v1.9  Conformance.txt  Sonobuoy  CNCF - Certified Kubernetes  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "End-to-End Testing for Kubernetes (Part I) - kubetest",
    "url": "/blog/e2e-testing-for-kubernetes-part-i/",
    "categories": "Kubernetes",
    "tags": "kubernetes, testing",
    "date": "2019-10-26 01:16:19 +0800",
    





    "snippet": "現今 Kubernetes Cluster 部署方式越來越多種，部署門檻也越來越低，但是在部署完之後要如何確認自己的 Cluster 真的是正常可用的？ 大多數的人(包含筆者以前)都是簡單部署一些 Deployment 或是 Service 看是否有 running 就認為 Cluster 是正常的，或是部署時沒有看到什麼錯誤訊息就覺得沒事，但是這樣是不太足夠的，因為有可能壞掉的是一些不常使用的功能或是人工比較難已發現的問題，這樣之後如果使用者部署應用時剛好使用到相關功能，發生問題將會很難查找。為了確認 Cluster 功能是否正常，我們可以針對 Cluster 做完整的測試，測試各個API是否正常，但是筆者查了一下發現網路上比較少關於 Kubernetes 測試的詳細資訊，因此花了一點時間研究並紀錄在此系列文章。  注意， Kubernetes 的測試有非常多種層面，例如： Unit Testing 、 Integration Testing 、 E2E Testing 、 Performance/Benchmark Testing 、 Load Testing 、 Stress Testing 或是 Security Testing，但是在此系列文中，強調的是測試 Cluster 的功能是否正常，因此重點會放在 E2E Testing 上。E2E Testing for Kubernetes:  End-to-End Testing for Kubernetes (Part I) - kubetest  End-to-End Testing for Kubernetes (Part II) - Conformance Testing另外筆者在 Cloud Native Taiwan User Group (CNTUG) Meetup #20 也有一場 talk 是在介紹這個主題，大家可以參考以下的簡報：Software Testing一般 Software Testing 可分成三種比較常見的測試方式:Unit Testing單元測試，測試單一功能或是某個函數，例如測試登入功能是否正常。這種測試維度比較小，測試程式的撰寫也比較單純一點。Integration Testing整合測試，這種通常是測試多個具有關聯或相依性的功能(或函數)整合之後是否正常，維度比單元測試還要大一點。End to End (E2E) Testing前面單元測試跟整合測試兩個都是比較偏向 Developer 驗證 Code 或是函數是否正常，而 E2E 測試比較偏向以使用者角度去操作系統，測試人員把自己當成一般使用者去對整個系統做操作，測試每個功能是否正常。由於我們只是要確認 Kubernetes Cluster 功能是否正常，並不是要開發，因此此系列文會著重在 Kubernetes E2E Testing。SIG-TestingSpecial Interest Group (SIG) 是由一群志同道合來自各公司各領域的人組成的組織或是團體，主要是一起學習某個技術、對某個技術進行探討或是一起維護某個專案，類似社群的概念，這些 SIG 可能也會定期的舉辦 Meetup 或是 Conference 等。 Kubernetes Community 是由許多不同的 SIG 組成，例如: sig-network 是負責 Kubernetes 中網路部分、 sig-docs 是負責文件、而 sig-storage 是負責儲存部分等等。每個 SIG 都有自己負責的 Subproject ，這些 Subproject 可能是文件撰寫，也有可能是 Code 撰寫。除了 SIG 之外，Kubnernetes Community還有其他的 Subgroups 如 Committees 、Working Groups 跟 User Groups 等等，如果對於 Kubernetes Community 組成有興趣，可以參考: Kubernetes Community Governance Model 。如果想了解 Kubernetes 中各個 SIG，可以參考: Kubernetes SIGs and Working Groups。如果想了解各個 SIG 負責的 Subproject ，可以參考: Subprojects of each SIGs。在眾多 SIG 當中，負責 Kubernetes 測試的是 sig-testing ， sig-testing 負責許多知名的 subprojects ，如管理      Kubernetes project 的 CI/CD 系統 - prow ，以及部署 K8s in docker 的 kind 等等。在這裡我們主要會提到的是 - test-infra 。 test-infra 提供了許多供 Kubernetes 測試的工具，裡面包含了我們要介紹的 Kubernetes E2E Testing Tool - kubetest。Cluster E2E TestingKubernetes E2E Testing 主要是驗證所有的功能 (包含 API Server 以及 Controller ) 是否是正常可用的，且 API 行為必須跟 Spec 上一樣。透過這種測試能夠找出一些 Unit Test 、 Integration Test 或是人工難以找出的問題。Kubetest Usagetest-infra 釋出了可以對 Kubernetes Cluster 做 E2E Test 的工具 - kubetest ，不過 kubetest 其實是一個整合的介面，他不只可以做一般的 E2E Test ，還整合了如 Conformance Test, Node E2E Test 以及 Performance Test 等等的測試，後續我們會再細部介紹 kubetest 的運作流程。這邊需要注意的是: kubetest 在執行 E2E Test 時，會開啟一個乾淨的 Cluster 來做測試，這樣的用意是因為  Kubernetes 是想要針對整個 Kubernetes Source Code 做 E2E Test ，這樣才可以確保當前 Release 出來的 Kubernetes 版本是正常可用的。 因此 kubetest 在執行時會去尋找 Kubernetes Repository ，找到後再 Build Source Code ，接著開啟新的 Cluster 測試。  kubetest 其實也有被整合到 prow 裡面，任何 Pull Requet 在被 Merge 前，也都會透過 kubetest 進行測試。Execution:$ kubetest --build --provider &amp;lt;yourprovider&amp;gt; --deployment &amp;lt;yourdeployer&amp;gt; --up --test --test_args=&quot;--ginkgo.skip(focus)=xxx&quot; --dump &amp;lt;folder&amp;gt; --down  Flag:--build:       Build binaries (e2e.test, e2e_node.test) for testing.--provider:    Specify an alternative provider (gce, local, gke, aks, etc.) for E2E testing, default value is gce. --deployment:  Deployment strategies of Kubernetes cluster.  (gce, local, gke, aks, etc.)--up:          Turn up a new cluster.     --test:        Run E2E testing.--test_args:   Test matching for ginkgo.--down:        Shutdown and delete the cluster.--dump:        Export the result. ( junit xml format )這邊比較容易搞混的是 --provider 以及 --deployment ，官方文件對這兩個 flag 並沒有太多的解釋，經過筆者研究了之後，整理出來結論是: --provider 比較像是告訴 kubetest 要在哪個平台上做測試或著是告訴 kubetest 準備哪一個平台使用的 Test Lists，而 --deployment 比較像是告訴 kubetest 你的 Cluster 位置，讓 kubetest 可以存取到 Cluster 。舉例來說如果你設定 --deployment gke ， kubetest 就會知道你的 Cluster 是用 gke 佈出來的，接下來就會等你再提供一些 gke 相關參數(例如提供 kubeconfig 或是一些 token 之類的)，讓 kubetest 能夠存取得到你的 Cluster 。需要注意的是 --provider 跟 --deployment 兩個平台必須一致，否則 kubetest 會無法測試並且報錯，例如 --provider local 配上 --deployment gke 或是 --provider gke 配 --deployment local 這種情況是不行的。  筆者實際執行完整的 E2E Test 大概花了一天左右，不過可能跟筆者 Homelab 硬體資源有關，實際上應該不需要這多時間。使用 --dump flag 會將測試結果存成 JUnit 格式，裡面會寫所有執行的測項以及測試結果 (包括失敗訊息):Kubetest Workflow接下來解釋一下 kubetest 運作流程，到底執行 kubetest 之後它做哪些事情呢？上圖為 kubetest 簡單的執行流程圖，基本上大致流程是 kubernetes/hack/e2e.go -&amp;gt; test-infra/kubetest -&amp;gt; kubernetes/hack/ginkgo-e2e.sh -&amp;gt; kubernetes/test/e2e/e2e_test.go -&amp;gt; kubernetes/test/e2e/framework/framework.go -&amp;gt; Start E2E testing 。Stage 1: kubernetes/hack/e2e.go -&amp;gt; test-infra/kubetestkubernetes/hack/e2e.go在以往還沒有 kubetest 的時候， Kubernetes 測試都是各自分開的介面，而其中 E2E Testing 部分就是 kubernetes/hack/e2e.go 負責，但是 sig-testing 可能是為了整合這些介面，因此開發了 kubetest ，來讓測試人員能夠直接使用單一介面來做到各式各樣的測試( Cluster E2E Test 、 Node E2E Test 或 Performance Test 等等)。如果你直接去看 kubernetes/hack/e2e.go 的 Source Code，你會發現其實它也是會去抓 kubetest 並且執行 kubetest ，所以你可能會看到網路上一些文章介紹 E2E Testing 的時候是執行 hack/e2e.go --provider xxx ... 而不是 kubetest --provider ... ，這兩個其實是一樣的。如果你去看 kubernetes/hack/e2e.go 的 history ，可以看到他在2017年的時候把 Code 整個改成 kubetest 介面，由此可以得知是從那個時候開始整合進去的。Stage 2: test-infra/kubetest -&amp;gt; kubernetes/hack/ginkgo-e2e.shGinkgo &amp;amp; GomegaKubernetes E2E Testing 所有測項其實都是用 Ginkgo 以及 Gomega 撰寫的， Ginkgo 是 Golang 的 Behavior-Driven Development (BDD) Testing Framework ，而 Gomaga 是 Golang 的 Matcher Library， 用在測項結果比對。這邊簡單解釋一下 BDD 為何，一般在做 Software Testing 時， RD 或是 QA 可能會依照規格書撰寫出對應的測試 Code ，但是這些 Code 可能只有技術人員看得懂，這樣會導致技術與非技術人員很難協同作業或討論，因此很容易發生開發者誤解測項或是規格書制定不清楚的情況。而 BDD 就是為了解決這個問題，讓開發人員以及非技術人員能夠一同協作的一種開發方式，首先大家會共同制定一份規格書，規格書會使用更接近人類語意的自然語言來描述軟體功能和測試案例，制定完後， QA 能夠直接執行這份規格書來測試，無需再額外寫一些複雜的測試 Code，簡單來說 BDD 就是以軟體的行為來描述測試，讓大家都能看懂。Ginkgo 主要由以下三個部分組成：  Main Program: 主要要測的程式。  Test Suite: 測試包，通常會包含很多 Spec (測項)。  Spec: 測項 (可能一個或多個)。以下使用簡單的範例來介紹如何使用 Ginkgo 和 Gomaga ，範例 Code 可以從筆者 GitHub 上下載，有興趣可以去載下來執行看看。  下載並安裝 Ginkgo 和 Gomega    $ go get github.com/onsi/ginkgo/ginkgo$ go get github.com/onsi/gomega/...# Install Ginkgo CLI$ go install github.com/onsi/ginkgo/ginkgo            這邊撰寫一個簡單的 myproject package ，裡面會有兩個函數: Greeting() 和 Calc() 。 Greeting() 功能是是傳入一個字串，會回傳 Hello xxx 的打招呼函數； Calc() 是傳入一個數值，會回傳十倍的值給你。    myproject.go    package myprojectfunc Greeting(name string) string{    return &quot;Hello &quot; + name + &quot;.&quot;}func Calc(number int) int{    return number * 10}        新增 Test Suite ， Test Suite 就是測試包的意思，測試包會去抓所有的測試檔，並執行裡面的測項 ( Spec )。    $ cd myproject$ lsmyproject.go$ ginkgo bootstrap$ lsmyproject.go myproject_suite_test.go            查看 Test Suite ，會發現裡面會有一個 Testxxx() 函數。預設 Golang 本身就有支援測試的功能 ( go test )，當執行 go test 後， go 會去抓目錄底下所有 xxx_test.go 的檔案，並執行這些 go 檔裡面 Testxxx() 的函數，這些函數就是你寫的測項。 Ginkgo 也是使用 go test 這種特性，讓 go 先去執行 Testxxx()，只不過在這個 Testxxx() 函數裡執行的是 Ginkgo 的函數 RunSpecs() ， RunSpecs() 會去抓目錄底下所有的測項 ( Spec ) 。    myproject_suite_test.go    package myproject_test import (      &quot;testing&quot;      . &quot;github.com/onsi/ginkgo&quot;      . &quot;github.com/onsi/gomega&quot;)func TestMyproject(t *testing.T) {      RegisterFailHandler(Fail)      RunSpecs(t, &quot;Myproject Suite&quot;)}        接著就是產生測試檔    $ ginkgo generate mytest$ lsmyproject.go myproject_suite_test.go mytest_test.go        mytest_test.go     package myproject_test  import (         . &quot;github.com/onsi/ginkgo&quot;         . &quot;github.com/onsi/gomega&quot;         . &quot;github.com/myproject&quot; ) var _ = Describe(&quot;Mytest&quot;, func() { })            撰寫測項 ( Spec ) ，如果你曾經有寫過其他語言的測試，你可能會發現 Ginkgo 架構與他們非常相似，都是由三個部分組成: Describe , Context 以及 It ， Describe 是描述這個 Spec ，例如: 測試 Greeting() 函數 。 Context 是補充說明這個 Spec ，可以增加條件式或是任何規則還讓 Spec 行為更加明確，例如： 傳給它一個字串 或是 傳給它一個中英文夾雜的字串 等等。最後 It 是預期達到的結果，例如： 應該要跟我打招呼 , 要回傳什麼值 或 要報錯 等等。    在此範例中， Spec 1 是測試傳入一個字串給 Greeing() ，驗證是否會回傳 Hello &amp;lt;字串&amp;gt;。 Spec 2 是測試傳入一個數值給 Calc() ，驗證是否會回傳十倍的值。    mytest_test.go     ... var _ = Describe(&quot;Mytest&quot;, func() {     var name string= &quot;test&quot;     var number int= 99     // Spec 1     Describe(&quot;Test Greeting function&quot;, func() {             Context(&quot;Giva a name&quot;, func() {                 It(&quot;Should greeting&quot;, func() {                     Expect(Greeting(name)).To(Equal(&quot;Hello &quot;+name+&quot;.&quot;))                 })             })     })     // Spec 2     Describe(&quot;Test Calc function&quot;, func() {             Context(&quot;Give a number&quot;, func() {                 It(&quot;Should get the correct result&quot;, func() {                     Expect(Calc(number)).To(Equal(number*10))                 })             })     }) })        另一個範例是 Ginkgo 的一個函數 BeforeEach() ，由於 Kubernetes 的 E2E Test 中使用了很多 BeforeEach ，因此這裡特別解釋一下 BeforeEach  的作用。 BeforeEach 執行時機是在 每個 Spec 執行前 ，我們可以將一些參數初始化的步驟或是一些可能會被 Spec 影響的步驟放到 BeforeEach 裡面，這樣可以確保每次的測試都是公平乾淨且不受影響的。    從底下例子來看，我們宣告一個 number 並給它值 99 ， Spec 1 會去執行驗證 Calc() 函數，驗證完後會把 number 值改掉，如果沒有把 number = 99 放到 BeforeEach() 裡面，那 Spec 2 就會直接使用 被改過 的 number ( 這時應該是  990 ) 去做測試，然後就會測失敗，因此必須將 number = 99 放到 BeforeEach() 裡面，讓 Ginkgo 執行每個 Spec 之前都重新指派一次 number 的值。    mytest2_test.go     …  var _ = Describe(&quot;Mytest&quot;, func() {     var number int     // 如果將 number 指派放到 BeforeEach 外面，則 number 的值會被 Spec 1 改掉。     // number = 99     BeforeEach(func(){         // 將number 指派放到 BeforeEach 裡面可以確保值永遠都是 99         number  = 99     })     Describe(&quot;Test Calc function again&quot;, func() {         Context(&quot;Give a number 99&quot;, func() {             // Spec 1              It(&quot;Should return 990&quot;, func() {                 Expect(Calc(number)).To(Equal(990))                 number = Calc(number2)             })             // Spec 2             It(&quot;Should return 990, too&quot;, func() {                 Expect(Calc(number)).To(Equal(990))             })         })     }) })           執行測試，我們可以直接使用 ginkgo 或是 go test 指令來執行測試。執行完後 Ginkgo 會顯示執行了幾個 Spec ，然後幾個成功幾個失敗。    $ ginkgo# Show all Specs$ ginkgo -vRunning Suite: Myproject Suite==============================Random Seed: 1568041760Will run 4 of 4 Specs•••Ran 4 of 4 Specs in 0.001 secondsSUCCESS! -- 4 Passed | 0 Failed | 0 Pending | 0 SkippedPASSGinkgo ran 1 suite in 3.471827325sTest Suite Passed        到這邊大概了解 Ginkgo 的作用後，接下來我們回到 test-infra/kubetest ，根據程式碼來看一下 kubetest 做的事。    當我們執行 kubetest --test 的時候， test-infra/kubetest/main.go 會去執行 complete() 函數，接著根據指定的 --deployment 執行 run(deploy, *o)。    test-infra/kubetest/main.go    ...func main() {   ...   err := complete(o)   ...}func complete(o *options) error {   ...   if err := run(deploy, *o); err != nil {      return err   }   ...}...        test-infra/kubetest/e2e.go 裡的 run() 函數，會判斷是否有設定 --test flag，有得話就執行 Run() 來做 E2E test ，可以看到 Run() 函數裡會去呼叫 ginkgo-e2e.sh 。    test-infra/kubetest/e2e.go    ...func run(deploy deployer, o options) error {   ...   // 判斷是否有設定 --test flag   if o.test {      // 判斷是否有 build 了 e2e.test      if err := control.XMLWrap(&amp;amp;suite, &quot;test setup&quot;, deploy.TestSetup); err != nil {         ...      }       ...      else {         if o.deployment != &quot;conformance&quot; {            ...         }         ...         else{            ...            if tester != nil {               // 開始測試               return tester.Run(control, testArgs);		            }            ...         }       }   }      }...// Run executes ./hack/ginkgo-e2e.shfunc (t *GinkgoScriptTester) Run(control *process.Control, testArgs []string) error {   return control.FinishRunning(exec.Command(&quot;./hack/ginkgo-e2e.sh&quot;, testArgs...))}        由此可以知道 kubetest 其實是使用 Ginkgo 來執行所有測項，並且會執行 ginkgo-e2e.sh。  Stage 3: kubernetes/hack/ginkgo-e2e.sh -&amp;gt; kubernetes/test/e2e/e2e_test.go -&amp;gt; kubernetes/test/e2e/framework/framework.go在 Stage 2 我們已經知道 kubetest 會執行 Ginkgo ， 接下來解釋到底 Test Lists 在哪裡。我們實際去看 kubernetes/hack/ginkgo-e2e.sh 原始碼，會看到 Ginkgo 會去執行 e2e.test。kubernetes/hack/ginkgo-e2e.sh...# Find the ginkgo binary build as part of the release.ginkgo=$(kube::util::find-binary &quot;ginkgo&quot;)e2e_test=$(kube::util::find-binary &quot;e2e.test&quot;)...&quot;${ginkgo}&quot; &quot;${ginkgo_args[@]:+${ginkgo_args[@]}}&quot; &quot;${e2e_test}&quot; -- \\  &quot;${auth_config[@]:+${auth_config[@]}}&quot; \\  --ginkgo.flakeAttempts=&quot;${FLAKE_ATTEMPTS}&quot; \\...e2e.test 就是 Test Suite 以及 測項的 Binary 檔，前面我們有提到 kubetest --build 會去 Build Kubernetes Source Code ，其中一個就是把 kubernetes/test/e2e Build 成 e2e.test (可參考 BUILD)。  這邊 Build 其實就是做 make 的動作，如果對於 make 細節有興趣，可以去研究 Kubernetes 目錄裡的 Makefile 。我們再回到 kubetest 原始碼來看實際步驟，當執行 kubetest --build 時，test-infra/kubetest/main.go 會去執行 Build() 函數，而這個 BUild() 函數是位於 test-infra/kubetest/build.go 裡。test-infra/kubetest/main.gofunc acquireKubernetes(o *options, d deployer) error {   // Potentially build kubernetes   // 判斷有沒有設定 --build flag	if o.build.Enabled() {		var err error		// kind deployer manages build		if k, ok := d.(*kind.Deployer); ok {			err = control.XMLWrap(&amp;amp;suite, &quot;Build&quot;, k.Build)		} else {         // o.build.Build 就是 kubetest --build=&quot;值&quot; 指定的值，如果沒指定         // 預設是  quick-release			err = control.XMLWrap(&amp;amp;suite, &quot;Build&quot;, o.build.Build)		}		...   }}Build() 函數會實際去執行 make 來 Build Source Code 。test-infra/kubetest/build.gofunc (b *buildStrategy) Build() error {	var target string	switch *b {	case &quot;bazel&quot;:		target = &quot;bazel-release&quot;	case &quot;e2e&quot;:		//TODO(Q-Lee): we should have a better way of build just the e2e tests		target = &quot;bazel-release&quot;      ...	case &quot;host-go&quot;:		target = &quot;all&quot;	case &quot;quick&quot;:		target = &quot;quick-release&quot;	case &quot;release&quot;:		target = &quot;release&quot;	case &quot;gce-windows-bazel&quot;:		...	default:		return fmt.Errorf(&quot;Unknown build strategy: %v&quot;, b)	}   ...	// 執行 make -C kubernetes &amp;lt;target&amp;gt;	return control.FinishRunning(exec.Command(&quot;make&quot;, &quot;-C&quot;, util.K8s(&quot;kubernetes&quot;), target))}到這邊我們已經知道 kubetest --build 執行細節以及 e2e.test 的由來，接下來我們再討論 e2e.test 裡的 Test Suite 以及 Spec 到底是什麼？Test Suite前面有提到 Golang 在執行 go test 時會去找 xxx_test.go 的檔案，並且執行裡面的 Testxxx() 函數。因此當 Ginkgo 執行 e2e.test 時，會找到 kubernetes/test/e2e/e2e_test.go 檔，然後去執行 kubernetes/test/e2e/e2e.go 裡面的 TestE2E() 函數。kubernetes/test/e2e/e2e_test.gofunc TestE2E(t *testing.T) {	RunE2ETests(t)}TestE2E() 函數會執行 Ginkgo 函數 RunSpec() 來執行所有 Spec，由此可以知道 e2e_test.go 以及 e2e.go 就是 Test Suite 。kubernetes/test/e2e/e2e.gofunc RunE2ETests(t *testing.T) {   ...   ginkgo.RunSpecsWithDefaultAndCustomReporters(t, &quot;Kubernetes e2e suite&quot;, r)}Specs一般來說使用 Ginkgo 來做測試，為了方便 Test Suite 去抓到所有的 Spec ，會在 Test Suite 檔案 Import Spec 的 {ackage (除非 Spec 與 Test Suite 同個 Package )，所以如果直接從 e2e_test.go 以及 e2e.go 去看，就會發現在 e2e_test.go 裡 Import 了所有 E2E Test 用到的 Spec ，可以發現這些測項就是位於 kubernetes/test/e2e/ 底下。kubernetes/test/e2e/e2e_test.gopackage e2eimport (   &quot;flag&quot;   ...   // test sources	_ &quot;k8s.io/kubernetes/test/e2e/apimachinery&quot;	_ &quot;k8s.io/kubernetes/test/e2e/apps&quot;	_ &quot;k8s.io/kubernetes/test/e2e/auth&quot;	_ &quot;k8s.io/kubernetes/test/e2e/autoscaling&quot;	_ &quot;k8s.io/kubernetes/test/e2e/cloud&quot;	_ &quot;k8s.io/kubernetes/test/e2e/common&quot;	_ &quot;k8s.io/kubernetes/test/e2e/instrumentation&quot;	_ &quot;k8s.io/kubernetes/test/e2e/kubectl&quot;	_ &quot;k8s.io/kubernetes/test/e2e/lifecycle&quot;	_ &quot;k8s.io/kubernetes/test/e2e/lifecycle/bootstrap&quot;	_ &quot;k8s.io/kubernetes/test/e2e/network&quot;	_ &quot;k8s.io/kubernetes/test/e2e/node&quot;	_ &quot;k8s.io/kubernetes/test/e2e/scheduling&quot;	_ &quot;k8s.io/kubernetes/test/e2e/servicecatalog&quot;	_ &quot;k8s.io/kubernetes/test/e2e/storage&quot;	_ &quot;k8s.io/kubernetes/test/e2e/storage/external&quot;	_ &quot;k8s.io/kubernetes/test/e2e/ui&quot;	_ &quot;k8s.io/kubernetes/test/e2e/windows&quot;)...從裡面挑了一個 Spec 來看，可以看到 Spec 格式就是使用 Ginkgo 以及 Gomega 寫出來的。kubernetes/test/e2e/ui/dashboard.gopackage ui...var _ = SIGDescribe(&quot;Kubernetes Dashboard [Feature:Dashboard]&quot;, func() {	ginkgo.BeforeEach(func() {		// TODO(kubernetes/kubernetes#61559): Enable dashboard here rather than skip the test.		framework.SkipIfProviderIs(&quot;gke&quot;)	})	const (		uiServiceName = &quot;kubernetes-dashboard&quot;		uiAppName     = uiServiceName		uiNamespace   = metav1.NamespaceSystem		serverStartTimeout = 1 * time.Minute	)	f := framework.NewDefaultFramework(uiServiceName)	ginkgo.It(&quot;should check that the kubernetes-dashboard instance is alive&quot;, func() {		ginkgo.By(&quot;Checking whether the kubernetes-dashboard service exists.&quot;)		err := framework.WaitForService(f.ClientSet, uiNamespace, uiServiceName, true, framework.Poll, framework.ServiceStartTimeout)		framework.ExpectNoError(err)		ginkgo.By(&quot;Checking to make sure the kubernetes-dashboard pods are running&quot;)		selector := Labels.SelectorFromSet(Labels.Set(map[string]string{&quot;k8s-app&quot;: uiAppName}))		err = testutils.WaitForPodsWithLabelRunning(f.ClientSet, uiNamespace, selector)		framework.ExpectNoError(err)		ginkgo.By(&quot;Checking to make sure we get a response from the kubernetes-dashboard.&quot;)		err = wait.Poll(framework.Poll, serverStartTimeout, func() (bool, error) {			var status int			proxyRequest, errProxy := e2eservice.GetServicesProxyRequest(f.ClientSet, f.ClientSet.CoreV1().RESTClient().Get())			if errProxy != nil {				framework.Logf(&quot;Get services proxy request failed: %v&quot;, errProxy)			}			ctx, cancel := context.WithTimeout(context.Background(), framework.SingleCallTimeout)			defer cancel()			// Query against the proxy URL for the kubernetes-dashboard service.			err := proxyRequest.Namespace(uiNamespace).				Context(ctx).				Name(utilnet.JoinSchemeNamePort(&quot;https&quot;, uiServiceName, &quot;&quot;)).				Timeout(framework.SingleCallTimeout).				Do().				StatusCode(&amp;amp;status).				Error()			if err != nil {				if ctx.Err() != nil {					framework.Failf(&quot;Request to kubernetes-dashboard failed: %v&quot;, err)					return true, err				}				framework.Logf(&quot;Request to kubernetes-dashboard failed: %v&quot;, err)			} else if status != http.StatusOK {				framework.Logf(&quot;Unexpected status from kubernetes-dashboard: %v&quot;, status)			}			// Don&#39;t return err here as it aborts polling.			return status == http.StatusOK, nil		})		framework.ExpectNoError(err)	})})  此 Spec 是檢查 kubernetes dashboard 是否正常執行Kind of Tests從前面小節我們得知 Kubernetes E2E Testing 的測項，但是這些測項非常的多，要如何區別這些測項呢? Kubernetes 針對這部份採用了賦予 Label 的方式來區別不同種類的測項。  [Slow] - 執行時間超過兩分鐘的測項。  [Serial] - 需要依序執行，而不能平行執行的測項。  [Disruptive] - 具有破壞性或是會影響其他測試的測項，例如重開機 node ，或是砍掉 kube-system 相關的 pod 等等。  [Internet] - 會需要連到外部網路的測項。  [Conformance] - Conformace Testing 的測項。  [LinuxOnly] - 只能跑在 Linux node 的測項。  [Privileged] - 會需要 privileged container 的測項。  [Alpha] - 測試 Alpha 功能的測項。…詳細 Label 資訊可以參考 - Kinds of tests一個測項 ( Spec ) 可以貼上一個或是多個 Label ，貼的位置可以在 SIGDescribe 或是 Ginkgo.It ，如以下範例：ginkgo.It(&quot;should provide Internet connection for containers [Feature:Networking-IPv6][Experimental][LinuxOnly]&quot;, func() {		// IPv6 is not supported on Windows.		framework.SkipIfNodeOSDistroIs(&quot;windows&quot;)		ginkgo.By(&quot;Running container which tries to connect to 2001:4860:4860::8888&quot;)		framework.ExpectNoError(			framework.CheckConnectivityToHost(f, &quot;&quot;, &quot;connectivity-test&quot;, &quot;2001:4860:4860::8888&quot;, 53, 30))})...var _ = SIGDescribe(&quot;Kubernetes Dashboard [Feature:Dashboard]&quot;, func() {	ginkgo.BeforeEach(func() {		framework.SkipIfProviderIs(&quot;gke&quot;)   })...Execute Specific Kind of Tests在 kubetest 使用上，要過濾或是執行特定的測項，只需要使用 --test_args flag 然後裡面再設定 --ginkgo.focus/skip 就可以了。--test_args 是讓 kubetest 可以使用 Ginkgo CLI 的 flag ，因此不單單可以用 focus/skip ，只要是 Ginkgo CLI 支援的 flag ，基本上都可以使用。focus/skip 可以透過正規表示式來比對 Describe 或是 ginkgo.It 描述裡的 Label。# Only execute tests with LinuxOnly Label.$ kubetest --test --test_args=&quot;--ginkgo.focus=\\[LinuxOnly\\]&quot; --provider local --deployment local# Skip the tests with LinuxOnly Label.$ kubetest --test --test_args=&quot;--ginkgo.skip=\\[LinuxOnly\\]&quot; --provider local --deployment local  focus/skip 可以用來比對 Describe 或是 ginkgo.It 描述裡的 Label。framework.gokubernetes/test/e2e/framework/framework.go 是用來執行一些 E2E test 會使用到的函數，如後續會提到的 Conformance Testing 就是在 framework.go 裡執行 framework.ConformanceIt() 來做貼 Label 的動作。其餘 framework.go 細節筆者就沒深入去瞭解，因此這部分就不深入解釋。Write Your Own Test在了解 kubetest 流程之後，接下來我們來試著撰寫自己的測試。SpecificationsKubernetes Community 在 Writing good e2e tests for Kubernetes 裡提到一些撰寫測試前需要注意的事項以及一些規範，大致為以下幾項：      Debuggability : 在寫測試時盡量將所有訊息寫清楚，例如測試失敗時，失敗訊息要寫明確說是哪裡錯誤，不要就含糊的顯示「測試失敗」之類的訊息，必須讓測試人員容易去 Debug 。        Ability to run in non-dedicated test clusters :  不要限定測試只能跑在特定的 Cluster，這裡的意思是撰寫測試時不要有假設的情況，任何測項都要寫清楚。例如：假設這個 Cluster 是乾淨的，上面沒有跑任何服務、假設環境裡已經有 xxx 服務或是假設 Cluster 跑在什麼硬體、環境等等。這裡官方舉了一個例子: 假如今天寫了一個測試「確認你的 Pod 能跑在所有 Node 上」來驗證所有 Node 有沒有問題，這個測項看起來似乎沒問題，但是實際上做了一個「同時間內只有你這個測項跑在 Node 上或是同時間沒有其他服務在 Node 上」的假設。假如你在跑這項測試前， Cluster 正在同時跑其他測試(或是服務)，導致某個 Node 資源被佔滿或是執行到 [Disruptive] 的測項，這樣這個測試就會被影響而失敗，但是他的失敗並不是 Node 本身有問題，而是被其他東西影響，這樣測試出來就會不準確。    另外是盡量避免撰寫 [Disruptive] 的測項，我們前面有提到 [Disruptive] 是具破壞性的測項，可能會影響其他測試，例如：重開機、刪掉服務等等。這裡避免的意思一樣是不要假設：「同時間只有你這個測項在測試」，避免影響到其他測試或服務，如果真的要撰寫該類型的測試，一定要加 [Disruptive] Label，並且把測項描述寫清楚。    最後是盡量不要使用非 Kubernetes 官方的 API 來做測試，因為這樣測試失敗時很難找出是 API 問題還是 Cluster 問題。        Speed of execution : 在寫測試時，盡量提升測試的效率、壓低測試的時間，不要放一些如 sleep 這種耗時間的函數，如果測試時間會超過兩分鐘以上就加上 [Slow] Label，讓測試者知道這個是比較耗時的測項。    另外除了測試花的時間之外，還必須設定好測試失敗的時間，例如：你的測試很簡單只需要兩分鐘內完成，但是可能光是等 Pod Ready 就等超過兩分鐘甚至是 Pod 已經卡住了，如果沒有設定測試失敗的時間 (如10分鐘後就認定測試失敗) ，這個測試就會永遠卡在那。        Resilience to relatively rare, temporary infrastructure glitches or delays : 在寫測試時，要彈性一點，當遇到失敗的情況，多試幾次，有可能只是剛好一些情況導致失敗。舉例來說：你的測項是 「測試 Cluster 能不能跑起來 Nginx 的 Pod 」，有可能第一次在測剛好網路比較不穩， Image 抓比較慢或是抓不下來，導致測試失敗，但是第二次網路就恢復重抓就抓下來了，因此不要在第一次失敗就直接認定測試失敗，過個幾秒再重抓 Image 一次，測試就會正常了。    這裡需要注意的是，雖然說要給測項一些彈性，不過也是要根據你的測項來判斷適不適用。Add New Test了解測試撰寫規範之後，接下來就來實際撰寫測試，以下範例可以從我的 GitHub - kubernetes-e2e-practice 裡取得，有興趣者，可以載下來測試。  該範例適用於 Kubernetes v1.15.x 版本在這個範例裡， 我們會撰寫一個小測試驗證是否能在 Cluster 部署一個名為 pohsien 的 Pod ，並確認這個 Pod 是否成功執行起來。  首先在 kubernetes/test/e2e 新增一個 pohsien 資料夾，裡面就是放置我們自己撰寫的測試檔。    $ mkdir -c kubernetes/test/e2e/pohsien        接著撰寫自己的測試，並放置在剛剛建立的 kubernetes/test/e2e/pohsien/ 裡面，基本上這邊都是使用 client-go 來操作 Kubernetes 資源。我們定義一個 [Pohsien] Label ，然後把我們的測項貼上這個 Label ，以方便之後執行測試。    $ vim kubernetes/test/e2e/pohsien/pohsien.go$ vim kubernetes/test/e2e/pohsien/framework.go        pohsien.go     package pohsien ... var _ = SIGDescribe(&quot;Kubernetes Pohsien&#39;s Pod [Pohsien]&quot;, func() {         f := framework.NewDefaultFramework(&quot;pods&quot;)         var podClient *framework.PodClient                 ginkgo.BeforeEach(func() {                 podClient = f.PodClient()         })         ginkgo.It(&quot;Make sure the pohsien pod can be deployed&quot;, func(){             // 建立 pod              ginkgo.By(&quot;Create Pod&quot;)             pod := &amp;amp;corev1.Pod{                         ObjectMeta: metav1.ObjectMeta{                                 Name: &quot;pohsien&quot;,                                 Labels: map[string]string{                                         &quot;name&quot;: &quot;pohsien&quot;,                                 },                         },                         Spec: corev1.PodSpec{                                 Containers: []corev1.Container{                                         {                                                 Name:  &quot;nginx&quot;,                                                 Image: &quot;nginx:1.17.3&quot;,                                         },                                 },                         },                 }             podClient.Create(pod)                             // 檢查 pod 是否成功運行起來             ginkgo.By(&quot;Get the pod&quot;)                 podGetting, err := podClient.Get(pod.Name, metav1.GetOptions{})             framework.ExpectNoError(err, &quot;Failed to get the pod&quot;)             framework.ExpectNoError(f.WaitForPodRunning(podGetting.Name))             gomega.Expect(podGetting.Name, &quot;pohsien&quot;)         }) })        framework.go 是用來宣告 SIGDescribe() 函數，而其他的測試檔會呼叫這個函數並且傳遞相關參數(例如要設定的 Label 以及 Spec 等等），一般來說會在 framework.go 設定一些 Global 的設定或變數，例如幫整個該資料夾的測項貼上對應的 SIG Label。雖然 framework.go 應該不是必要的，但是為了與其他測項一致，因此在此範例我們也新增了 framework.go ，並且加上了我們虛構的 [pohsien-testing] Label 。 framework.go     package pohsien import &quot;github.com/onsi/ginkgo&quot; // SIGDescribe annotates the test with the SIG Label. func SIGDescribe(text string, body func()) bool {     return ginkgo.Describe(&quot;[pohsien-testing] &quot;+text, body) }        由於我們範例只是 Demo 用，因此在這裡並沒有特別嚴謹的指定 Label ，但請記得在撰寫自己的測試時一定要加上對應 Label ，如 [Slow] 、 [Serial] 、 [Disruptive] 等等，這樣可以讓測試人員更加了解你的測項的特性，如果不確定要加上哪些 Label 可以在 slack 或是 發佈 Issue / PR 時，標註 #kinds-of-tests 來詢問。    接下來在 kubernetes/test/e2e/e2e_test.go 裡面 Import 我們自己的測項。framework.go    package e2eimport (   &quot;flag&quot;   &quot;fmt&quot;   ...   // test sources   _ &quot;k8s.io/kubernetes/test/e2e/apimachinery&quot;   _ &quot;k8s.io/kubernetes/test/e2e/apps&quot;   ...   _ &quot;k8s.io/kubernetes/test/e2e/pohsien&quot;)...            接下來撰寫及修改 BUILD 檔來讓 kubetest --build 或是 make 時能抓到我們寫的測試檔。主要有兩個地方: 一個是在 kubernetes/test/e2e/pohsien/ 底下新增 BUILD 檔，另一個是在 kubernetes/test/e2e/BUILD 裡加上我們寫的測試檔。          BUILD 檔寫法可以參考其他 E2E 測項。        $ vim kubernetes/test/e2e/pohsien/BUILD$ vim kubernetes/test/e2e/BUILD            完成後，接下來我們就可以執行看看。    $ kubetest --build$ kubetest --test --test_args=&quot;--ginkgo.focus=\\[Pohsien\\]&quot;[pohsien-testing] Kubernetes Pohsien&#39;s Pod [Pohsien]Make sure the pohsien pod can be deployed/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/pohsien/pohsien.go:35...STEP: Create PodSTEP: Get the pod[AfterEach] [pohsien-testing] Kubernetes Pohsien&#39;s Pod [Pohsien]/root/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151Oct 25 09:33:54.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be readySTEP: Destroying namespace &quot;pods-1457&quot; for this suite.Oct 25 09:34:16.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discoveredOct 25 09:34:16.740: INFO: namespace pods-1457 deletion completed in 22.085125288sOct 25 09:34:16.742: INFO: Running AfterSuite actions on all nodesOct 25 09:34:16.742: INFO: Running AfterSuite actions on node 1Ran 1 of 4414 Specs in 28.369 secondsSUCCESS! -- 1 Passed | 0 Failed | 0 Pending | 4413 SkippedPASSGinkgo ran 1 suite in 29.513161526sTest Suite Passed2019/10/25 09:34:16 process.go:155: Step &#39;./hack/ginkgo-e2e.sh --ginkgo.focus=\\[Pohsien\\]&#39; finished in 29.787466628s      到這裡 Kubernetes E2E Testing 解釋就告一段落，下一篇文章會介紹如何在自己建立的 Cluster 做 E2E Test 。References  Types Of Software Testing: Different Testing Types With Details  WIKIPEDIA - Special Interest Group  Kubernetes SIGs and Working Groups  Kubernetes Community Governance Model  Subprojects of each SIGs  Sig-Testing  test-infra  Kubernetes E2E Testing  Kubetest  Ginkgo  Gomega  End-To-End Testing in Kubernetes  Writing good e2e tests for Kubernetes  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "ELK Filebeat With Log Rotate",
    "url": "/blog/elk-filebeat-with-log-rotate/",
    "categories": "Others",
    "tags": "ELK, log, system",
    "date": "2019-09-25 04:11:10 +0800",
    





    "snippet": "Log Rotate意思是當log隨著時間擴大後，能夠自動打包壓縮或是清除掉舊log，以免系統空間被log吃光。ELK Filebeat並無支援log rotate的功能，Beats主要功能是做log shipping，不包含log rotate，因此需要透過額外的方式做。  在此文章中測試環境為 Ubuntu Server 18.04 LTS方法1: logrotate Tool網路上查到大部分幾乎都是採用Linux內建的logrotate工具來配合Filebeat，一般Linux系統的套件如syslog, apt-get等等其實都已經有使用logrotate這個工具來做管理，這個工具可以設定定期或是根據大小來做rotate。以下為一個小範例:  在/var/log底下建立一個pohsien.log。```bash$ cd /var/log; vim pohsien.log$ ls -l pohsien.log-rw-r–r–  1 root root 204 Aug 20 09:47  pohsien.log```  將/var/log/pohsien.log加到logrotate設定檔裡面。     $ vim /etc/logrotate.conf        新增以下內容     /var/log/pohsien.log{     # 大小超過500KB就執行log rotate     maxsize 500K     # 將舊的檔案壓縮，並創建新的pohsien.log檔     # 如果沒壓縮的話，舊檔會改名，然後一樣會創建新的pohsien.log檔     compress     # 做超過兩次log rotate就把最舊的資料砍掉，也就是最多只會留兩個壓縮檔     rotate 2 }            測試log rotate 重複寫入pohsien.log然後手動執行logrotate，可以發現當檔案超過500KB，就會自動產生pohsien.log.x.gz，且最多只會有兩個壓縮檔，最舊的會一直被砍掉。    手動執行logrotate     $ logrotate -v /etc/logrotate.conf        查看結果     $ ls -l /var/log           注意事項在此範例中只有使用到一些功能，實際上logrotate可用的功能相當多，可視各種情境做調整。另外logrotate是使用cronjob執行的，在Ubuntu預設是15分鐘執行一次，如果想要自訂執行時間可以自己另外寫cronjob執行logrotate，另外要注意的是如果要跟filebeat一起使用，需要配合好兩個的執行時間。參考資料  鳥哥的Linux私房菜 Logrotate - http://linux.vbird.org/linux_basic/0570syslog.php#rotate  How to Use logrotate to Manage Log Files - https://www.linode.com/docs/uptime/logs/use-logrotate-to-manage-log-files/相關討論  Log rotation and filebeat - https://discuss.elastic.co/t/log-rotation-and-filebeat/140285方法2: 檢查filebeat registryElasticsearch staff在討論區 文章1跟文章2有提到一個比較tricky的方式:  filebeat每次成功傳送完檔案後會把記錄寫在/var/lib/filebeat/registry/filebeat/data.json  寫一隻cronjob或是其他程式檢查data.json裡的offset是否跟log檔案大小一樣，如果一樣就代表傳輸完了，然後刪掉傳輸完的log檔案。相關討論  Delete processed log entries - https://discuss.elastic.co/t/delete-processed-log-entries/75960  FileBeats -Are there any ways we can delete the log files after file beat harvest the data to logstash - https://discuss.elastic.co/t/filebeats-are-there-any-ways-we-can-delete-the-log-files-after-file-beat-harvest-the-data-to-logstash/177997  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "iThome Kubernetes Summit 2019 心得",
    "url": "/blog/2019-ithome-kubernetes-summit-notes/",
    "categories": "Kubernetes",
    "tags": "conference",
    "date": "2019-09-17 05:11:58 +0800",
    





    "snippet": "這次是第一次參加iThome Kubernetes Summit，當初看到早鳥票釋出就直接買了($2400左右)，以一天的Conference來說不算便宜，但是能夠去學習學習增廣見聞也是值得的。結果買票之後才得知我們社群Cloud Native Taiwan User Group(CNTUG)也有去擺攤，雖然是付費票，但是還是去支援了一下社群攤位xD。上午場都在跟附近社群交流、逛攤位以及顧社群攤位，因此只聽了第一場「賣K8s 的人不敢告訴你的事」。下午花比較多的時間在聽議程，以下列出部分議程的簡單心得跟筆記。目前官方已經有將簡報釋出，也有釋出當天大會各議程共筆，有興趣的人可以參考：議程: https://summit.ithome.com.tw/kubernetes/大會共筆: https://hackmd.io/@k8ssummit/19/%2FRe80SUVITjWAMbUwaUVnWw賣 K8s 的人不敢告訴你的事葉秉哲（William） / 新加坡商鈦坦科技 Technical CoachSlide這場議程大多比較偏向使用者在導入Kubernetes時需要思考的事，大部分賣K8s平台的廠商在協助導入Kubernetes的時候都只提到好處(好管理Container以及好Scale)，但是都沒有提到維運成本以及其他層面(Networking, Storage etc)。講者提到了在導入Kubernetes時，可以使用三種方式來更加了解及定位出自己的需求或目標：1. 任何事情不能只看表面，要了解現實面。使用5W1H(What,Where,When,Why,Who,How)分析法去了解事情，要深入的去了解事情，不能只單單看表面，講者這裡提到一些例子：Kubernetes官方對Kubernetes的介紹：OpenSource、Auto-Deployment、Containerized等等。這個時候可以去思考：  OpenSource如果出問題，有哪個廠商可以support嘛？  為什麼直到現在才有這種Auto-Deployment Container服務或著是跟現有的解決方案差別在哪？  我們真的做好自動化的準備嗎？我們的Service真的準備好Auto-Deployment了嗎？  為什麼會需要Containerized？  Service Containerized之後穩定嗎？  …iThome 遍地開花的K8s與容器應用文章，裡面提到K8s、容器化、微服務、部署跟管理方便以及Hybrid Cloud Solution等等。這個時候可以去思考：  為什麼需要微服務? 優缺點是什麼？  什麼情況下會需要Hybrid Cloud Solution，以及為什麼以前沒有推這種Solution?  …Kubernetes at GitHub，GitHub在自家服務使用Kubernetes的成功案例，他們一開始先對github.com以及api.github.com導入Kubernetes，且第一階段先把stateless服務遷移到Kubernetes上。先選擇github.com以及api.github.com的原因是因為這兩個服務導入最艱難，只要這兩個導入成功的，其他的應該就比較沒問題。導入的工作主要是由是SRE、Platform以及Developer三個一起參與導入。看到這些可以去思考：  為什麼導入要先以最艱難的服務導入？不是通常都會先用簡單或比較不重要的服務測試Kubernetes，然後再慢慢把重要的遷移上去嗎？GitHub這樣是有不同考量嗎？對我的企業而言哪種比較適合呢？  為什麼會需要SRE、Platform以及Developer三種工程師一起參與？缺少任一個可以嗎？  為何先挑選stateless服務做處理呢？2. 擴展自己的知識多擴展自己的知識，可以多看CNCF Cloud Native Interactive Landscape，瞭解project的分類，並且定位自己目前需要達成的是哪些目標，多了解一些，不要冒然選廠商跟解決方案。另外也可以參考CNCF Trail Map，裡面有提供十個階段來建議企業漸進式導入Cloud Native專案，可以詢問自己目前想要做的是哪一階段或是廠商提供的是哪一階段的服務？3. Dev跟Ops都需要了解要導入Kubernetes絕對不會只是Operation的事，Development也是相當重要的，善用各方面的知識，並且互相交流，才能夠降低導入Kubernetes的門檻。Docker Swarm 太陽春 K8s 太複雜？試試輕量級的 K3s 吧！王偉任（Weithenn） / Micron Technology Senior System Engineer這個議程主要是在介紹Rancher K3s，提到K3s比起一般Kubernetes還要更加的輕量化及差異點(SQLite取代etcd,預設Container Runtime使用containerd)。由於他非常的輕量，因此很適合部署在如樹莓派這樣的IoT裝置上，且部署方式非常方便，也能夠整合Kubernetes預設的dashboard或是Rancher Dashboard來做管理。Harden Your Kubernetes Cluster蔡宗城（smalltown） / Maicoin Senior Site Reliability Engineerslide此議程講者主要針對不同的層面來探討如何增強Kubernetes的安全性。講者提到了非常多實用的經驗跟工具，這裡有些部分沒有筆記到或是不清楚，建議可以直接看簡報比較詳細。Image  盡量使用Minimal Base Image，太大包的image可能會有不必要的套件，增加安全風險。  限制執行Container的使用者身份，以免讓Container取得過大的權限。  Image盡量不要使用latest版本，因為latest對應到的Image可能會一直變動。  不要隨意相信Registry上的Image，因為你無法確保那真的是官方釋出的。  可以使用簽章機制來識別官方釋出的Image，(可使用Notary)。  Image不要儲存一些敏感資訊，盡量用一些Secret形式來取代。  Use COPY instead of ADD  可使用 Anchor, Clair, Trivy來對image做CVE掃描，找出Image淺在的漏洞。  Regular Vulnerability Assessment -&amp;gt; 評估跟分類掃瞄出來的漏洞  DevSecOps -&amp;gt; 把image security 整合CI/CD。Credential  Kubernetes Secret放在Cluster裡不一定安全。  HashiCorp Vault -&amp;gt; 管理credentials 生命週期及儲存，支援Dynamic Credentials，可以整合public cloud或是DB。  Credentials Lifecycle：不要把Credentials 存在Disk，可存在Memory，使用完就直接清掉，不要保存。Network  預設情況下，Pod之間是沒有隔離的，網路都是互通。  Kubernetes Network Policy(須注意並不是每個CNI都有支援，slide裡連結有支援表可以參考)  Pod跟Pod之間傳輸是明碼的，很容易會有MITM。  Istio 裡面pod跟pod之間會有envoy proxy做傳輸，可以在這邊做手腳(Istio TLS)，將pod跟pod之間傳輸做加密。  Istio with Kiali ( 可以視覺化pod之間pod traffic流量，也會顯示連線是否有加密。Runtime(pod底層)分成兩個部分 Auditing &amp;amp; Enforcement  Enforcement -&amp;gt; 強迫去做一些事情(pod security policy, aurmor)  Falco -&amp;gt; 限定使用者不能做什麼事，例如使用者想要exec到pod執行bash，動作就會被擋住，然後Falco會傳通知給administrator。Policy as Code  Open Policy Agent (Kubernetes Admission Control, HTTP API Authorization)  OPA Flow，有點類似會有一個authorization/authentication server去對權限做管理，k8s在執行任何動作前都會去問authorization server來決定可不可以執行。  需注意OPA不是使用yaml來撰寫，是自己的語法。前方有雷別再踩─企業導入 Kubernetes 的掃雷指南朱培華 / 多奇數位創意系統工程師此議程的講者整理了非常多的Kubernetes Best Practice，從update, scaling, secret管理到label應用、資源應用以及監控等等，非常多實用的內容，這部分因為一些原因沒有記錄太多筆記，不過講者的簡報相當詳細，因此建議可以直接參考簡報。總結這裡筆者只列出一些議程筆記，其他比較偏安裝教學或是有些沒有筆記到的就沒有寫在這上面，有興趣者可以參考官方的共筆或是簡報。這次參加的感想是議程部分比較入門類，偏向經驗分享或是工具使用教學，很適合像筆者這樣的菜鳥新手去聽。攤位部分不多，大概只有幾家比較大的贊助商來擺攤，不過廠商贈品送的還蠻多的，另外這次很特別的是有來自國外的Dr.Brad Topol簽書會(書名Kubernetes in the Enterprise)，只要用名片就可以換到一本原文簽名書，算是這次Conference中最佛心的活動。最後還是覺得票價不便宜，希望明年有機會能夠當講者，除了能累積經驗外，也能使用講者票參加，一舉數得。Cloud Native Taiwan User Group攤位Kubernetes in the Enterprise作者簽書會  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "針對Enterprise PKS環境的K8s Cluster Node硬碟空間不足測試及解法",
    "url": "/blog/enterprise-pks-k8s-node-disk-out-of-space/",
    "categories": "Pivotal, Container, Service",
    "tags": "pks, kubernetes",
    "date": "2019-07-03 05:22:24 +0800",
    





    "snippet": "  此篇文章已不再更新，內容可能已過時這篇主要是測試Enterprise PKS佈出來的Kubernetes Node 上面的硬碟滿了會造成什麼影響以及要如何解決。其實這個問題應該跟一般Kubernetes環境差不多，只是目前有一些case緣故還是需要在Enterprise PKS環境下測試一下。因此特別針對這部分做測試。Kubernetes Node上的disk種類在PCF Ops Manager Web GUI &amp;gt; Enterprise PKS Tile &amp;gt; Plan裡，可以設定Enterprise PKS部署出來的Kubernetes Cluster資源，其中有一些欄位是設定node VM的硬碟資訊:預設BOSH產生出來的node上面會有三顆虛擬硬碟。這裡我們用sda,sdb,sdc來代稱。  sda: Node System Disk，掛載目錄為/，為node VM作業系統的根目錄，這個大小目前是不能設定的，預設3GB。  sdb: Agent Package Disk，掛載目錄為/var/vcap/data...，為存放pks-system以及bosh agent這些必要套件的位置，這個就是PCF Ops Manager上設定的VM Type裡面的disk大小。  sdc: Persistent Disk，掛載目錄/var/vcap/store/...，這個disk在master中是用來存etcd的，因此只要disk沒有掛掉，不管BOSH怎麼修復master，etcd資料都不會消失。如果是worker的話，這個disk是用來存docker container 以及docker image。sdc大小是根據PCF Ops Manager裡面設定的Persistent Disk Type來配置。  當node發生錯誤而啟動BOSH自動修復機制時，只有sdc資料會被保留，其他的都會被清空還原成初始狀態。  上面disk名稱只是方便識別，並非官方取名。由於disk裡的資料可能會隨著時間成長，例如:log, docker image/containe或是一些暫存檔等等。為了確定清楚硬碟塞爆是否會影響Kubernetes服務，因此接下來會測試塞爆三種disk並觀察會發生的情況。使用到的指令建立任意大小的檔案$ fallocate -l &amp;lt;檔案大小&amp;gt; &amp;lt;檔案名稱&amp;gt;Example:$ fallocate -l 50G test查看目錄屬於哪顆disk、大小及使用率$ df &amp;lt;目錄&amp;gt; -hExample:$ df /var/vcap/ -h查看目錄或檔案大小$ du -sh &amp;lt;檔案名稱/目錄&amp;gt;Example:$ du -sh /var/vcap/查看docker根目錄$ docker system info查看docker image/container數量/大小資訊$ docker system dfNode System Disk(sda)測試環境:  1台master, 2台worker測試結果  Container不會掛掉，正常運行。  BOSH ssh到worker的時候會顯示no space left on device錯誤。  修復方式          關閉壞掉的node讓BOSH自動修復，產生新的node VM。      如果還能登入node，可以清掉一些資料釋出Node System Disk(sda)空間。      測試流程      使用kubectl建立deployment到cluster上。    連到worker VM裡並塞滿sda空間     # SSH bosh -d &amp;lt;deployment&amp;gt; ssh &amp;lt;worker&amp;gt; # 切換到/dev/sda1掛載目錄 cd /var # 塞滿空間 fallocate -l 10G test        Container依然正常運行無異常，但是當執行bosh ssh時出現下圖空間不足錯誤。Agent Packages Disk(sdb)測試環境:  1台master, 2台worker測試結果  Node會掛掉，無法負荷原本的container，因此原本上面跑的container都會變成Evicted狀態。(可能會造成服務中斷)  如果有額外的node可用，master會佈新的container到別台node上。如果沒有，所有container都會變成Pending狀態。  修復方式:          清出Agent Packages Disk空間，然後執行monit restart all，這樣node就會恢復正常。      測試流程      使用kubectl建立deployment到cluster上。    連到worker VM(b685858b...)裡並塞滿sdb空間     # SSH bosh -d &amp;lt;deployment&amp;gt; ssh &amp;lt;worker&amp;gt; # 切換到/dev/sdb2掛載目錄 cd /var/vcap/data/ # 塞滿空間 fallocate -l 10G test            使用kubectl查看pods狀態，可以看到剛剛被塞爆的worker(b685858b...)上的pods都進入Evicted狀態，且master在其他node產生新的pods。     使用kubectl describe pods &amp;lt;pod name&amp;gt;查看Evicted pod，可以看到是因為node空間不足導致的。Persistent Disk(sdc)測試環境:  1台master, 2台worker測試結果  與Agent Packages Disk(sdb)結果相同  Node會掛掉，無法負荷原本的container，因此原本上面跑的container都會變成Evicted狀態。(可能會造成服務中斷)  如果有額外的node可用，master會佈新的container到別台node上。如果沒有，所有container都會變成Pending狀態。  修復方式:          清出persistent disk空間，然後在node上執行monit restart all指令，這樣node就會恢復正常。      測試流程      使用kubectl建立deployment到cluster上。    連到worker VM(3f28d443...)裡並塞滿sdb空間     # SSH bosh -d &amp;lt;deployment&amp;gt; ssh &amp;lt;worker&amp;gt; # 切換到/dev/sdc1掛載目錄 cd /var/vcap/store/docker # 塞滿空間 fallocate -l 50G test        使用kubectl查看pods狀態，可以看到剛剛被塞爆的worker(3f28d443...)上的pods都進入Evicted狀態，且master在其他node產生新的pods。擴大Node Disk大小看到上述測試可以得知disk如果滿了是有可能會影響服務，解決方法除了清掉不必要的檔案釋出空間之外，也可以選擇擴大原有的空間，但目前能擴大的只有sdb以及sdc。官方提供的擴大方式是到PCF Ops Manager去調原plan設定，例如把disk調大資源調多等等, 然後apply change的時候勾選upgrade all cluster, 這樣原有的cluster就會套用新的設定(cpu/memory/persistent disk…)，但只能修改原plan數值, 無法修改成不同plan(例如從plan1改成plan2)。詳情可參考連結 ，另外此方法的缺點是要改的話，全部同樣使用該plan的cluster都會一併修改。除了官方解法外，筆者我想到另外一種比較暴力的方法是直接在vCenter把node的硬碟擴大, 但是實際測試這種方式會導致BOSH那邊不同步引發錯誤，因此目前這是不可行的。以下是兩種方法的測試流程:PCF Ops Manager調整Plan設定      假設目前worker VM (91997fd5...) persistent disk已經被塞爆(預設50G)，希望能擴大空間。            到PCF Ops Manager Web GUI &amp;gt; Enterprise PKS Tile &amp;gt; Plan將worker的persistent disk調整成75G。            Apply Change            完成後連到worker VM(91997fd5...)去看，可以看到空間已經成功擴大。                Pod也可以正常的部署在worker VM (91997fd5...)上了。      從vCenter強制調整Node Disk大小  注意這種方式會導致BOSH那邊不同步引發錯誤，因此目前此方法是不可行的，但還是將過程列出來供參考。      假設目前worker VM (3f28d443...) persistent disk已經被塞爆(預設50G)，希望能擴大空間。            到vCenter上直接去將worker VM persistent disk調整為80G。            接下來為了避免BOSH將這台worker砍掉，因此要先關閉自動修復機制。    $ bosh -d &amp;lt;deployment&amp;gt; update-resurrection  off                接下來將worker VM(3f28d443...)關機。            可以從bosh vms看到該台worker1 已經變成unresponsive agent狀態，但是BOSH不會將它砍掉。            接下來到vCenter &amp;gt; Datastore &amp;gt; pcf_disks找到worker VM(3f28d443...)的persistent disk，並擴大它的空間。    先找出worker1對應的persistent disk(Disk CIDs)     $ bosh instances -i            到vCenter &amp;gt; Datastore &amp;gt; pcf_disks找到對應的disk，可以發現disk還是50G。        點擊inflate來擴大硬碟。(這個動作會跑一段時間)        好了之後可以看到disk已經變80G。            接下來將worker1開機，但是開好之後還是unresponsive agent。        不得已情況下只好將自動修復開起來，看看BOSH會不會砍掉建立新的worker，然後將persistent disk掛載上去。    $ bosh -d &amp;lt;deployment&amp;gt; update-resurrection  on                BOSH開始修復，但是修復到最後失敗，硬碟無法掛載，可能是因為disk裡的partition有變動到。到這裡就卡住了，BOSH就無法修復了，也許是某一步做錯或是BOSH本身不支援這種改法，後續如果有成功再來更新此篇，目前暫不將此方法列入解法。      Summary測試下來的感覺好像跟是不是Enterprise PKS環境沒啥關係xD。不過經過此測試也比較清楚Enterprise PKS運行機制以及針對這種情況的處理方式，但對目前的Enterprise PKS來說，擴大硬碟的機制還是很不彈性，這有可能是受到BOSH的限制，希望未來能夠再加強這部分。Reference  PKS Plan Resizing - https://community.pivotal.io/s/question/0D50e00005j9wr2/pks-plan-resizing  Changing the thick or thin provisioning of a virtual disk - https://kb.vmware.com/s/article/2014832  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "Enterprise PKS介紹",
    "url": "/blog/enterprise-pks-introduction/",
    "categories": "Pivotal, Container, Service",
    "tags": "pks, kubernetes",
    "date": "2019-06-28 08:06:57 +0800",
    





    "snippet": "  此篇文章已不再更新，內容可能已過時PKS全名是Pivotal Container Service，顧名思義是由Pivotal這間公司開發的。Pivotal是VMware的子公司，也許比較少人知道這間公司，不過相信大家應該都聽過tomcat或是redis，這兩個知名的專案就是由Pivotal開發的，由此可知Pivotal也是一家技術非常扎實強大的公司。PKS介紹PKS是用來管理/部署Kubernetes Cluster的一個平台，由於目前Kubernetes在建置或維運上還是需要蠻高的成本及技術門檻，為了要降低維運成本，讓企業能完全專注在自己的服務上，因此才漸漸開始有了這類管理/部署Kubernetes的平台出現。透過這種平台能夠輕鬆的部署Kubernetes Cluster，有些平台甚至還針對Kubernetes Cluster提供HA、Fault Tolerance或是Load Balancing的機制，大大降低維運成本，而PKS就是其中一種這種平台(產品)，類似的其他產品還有Rancher、Redhat OpenShift以及IBM Cloud Private等。目前Pivotal有三種不同的PKS產品：  VMware Enterprise PKS  VMware Essential PKS  VMware Cloud PKSVMware Enterprise PKS，目前為1.4.1版，在1.4.0以前名稱還叫做PKS而已，可能是因為要跟其他產品區分開來因而改名，這個產品架構主要是由Cloud Foundry開發的BOSH專案以及Pivotal各式產品組成，目前支援的平台為vSphere,GCP,Azure以及AWS，本篇會以Enterprise PKS介紹為主，稍後會有較詳細的架構介紹。VMware Essential PKS是今年2019年3月VMware出的一種新的PKS版本，這個版本比較特殊一點，主要是heptio公司(已被VMware買下來)開發的，因此他的架構主要都是由heptio所提供的Open Source套件組合而成的，例如用來備份Kubernetes的velero、或是作為proxy的contour等等。這個產品目前筆者也搞不清楚定位在哪，感覺與Pivotal開發的Enterprise PKS有較勁意味(Pivotal官方文件也完全沒有提到這個產品，都只有在VMware網站才有xD)，不過目前關於這產品的資訊還太少，也許過一段時間就會知道定位跟差異了。Cloud PKS是VMware提供的一個Public Cloud Kubernetes環境，是一個SaaS平台，使用者可以直接將Container部署上去，完全不需要維護Kubernetes環境，詳細資訊可以參考連結。PKS架構組成圖片為簡略的Enterprise PKS架構圖，由於Pivotal是VMware的子公司，因此目前Enterprise PKS對vSphere環境相容性最好，尤其是結合VMwaer NSX-T能夠完全發揮出Enterprise PKS功能。不過不管是運行在哪個平台，Enterprise PKS元件都會以VM的形式運行，因此是不會與平台中其他一般VM相衝突的。Enterprise PKS1. PCF Ops Manager這是Pivotal的一個產品，主要是提供一個GUI平台讓使用者可以直接上傳Pivotal系列產品來進行部署。Enterprise PKS也是透過這種方式安裝。Pivotal的產品是用Tile為單位(.pivotal檔)，只需要先將Tile上傳到Ops Manager，再手動設定一些參數(IP,密碼等等)，就可以直接按下變更鈕部署，非常方便。如果要刪掉產品也只要先按Tile旁邊的垃圾桶，再案變更鈕即可。如下圖所示，PCF Ops Manager上面有三個Tile，分別是BOSH Tile,PKS Tile以及Harbor Tile。PCF Ops Manager只是一個Tile管控介面，它一定要結合BOSH(下一點會提到)才能部署，所以實際上當使用者按下變更鈕之後應該是Ops Manager會呼叫BOSH Director去根據設定的參數部署這些Tile。  Pivotal官網有釋出許多它們包好的Tile，不過大部分都是他們自家的產品，是要付費的。如果想要自己做Tile，可以參照連結將自己的服務打包成Tile來安裝。2. BOSH DirectorBOSH是整個Enterprise PKS的核心，BOSH是由Cloud Foundry開發的Open Source專案，用來部署、監控、修復VM。而Cloud Foundry本身平台也是採用BOSH來建置的。在PKS當中，所有的元件包含後面提到的PKS API Server、Harbor或K8s Cluster都是由BOSH Director部署的，BOSH Director還會定期地去監控所有元件的健康狀態(每幾秒就polling一次)，只要發生有問題的元件，就會啟動自動修復機制，非常方便。3. PKS API ServerPKS API Server負責建置Kubernetes Cluster，不過這是比較攏統的說法，其實是PKS API Server收到Request之後，會通知BOSH Director部署K8s Cluster的Node(VM)，等到Node(VM)都建好後，PKS API Server就會開始針對這些VM去做設定及安裝一些PKS及Kubernetes的必要元件，如kube-proxy, kubelet, docker daemon等等。4. Kubernetes Cluster分成master以及worker，目前PKS佈出來的Kubernetes cluster都是佈在VM上面(畢竟一開始本來就是為vSphere打造的)。PKS可以一次部署多個Cluster，因此企業可以根據不同部門，給不同的Kubernetes Cluster並且指派不同的權限，且彼此是獨立開來的。所有透過BOSH Director跟PKS API Server部署出來的VM，上面都會預先裝好BOSH Agent以及PKS Service(Agent)，BOSH就是透過這些Agent來設定VM以及監控VM健康狀態。另外目前Enterprise PKS只支援Docker  Container，不確定之後會不會整合其他的Container Runtime。5. HarborHarbor是VMware釋出的一個開源Docker Container Registry，也是屬於CNCF裡的一個專案。Harbor其實並不屬於於PKS產品線的一員，只是通常Pivotal跟VMware會將它與PKS搭配在一起。從上面的架構圖可以看到兩個位於不同地方的Harbor，意思是Harbor有兩種安裝方式：一種是透過PCF Ops Manager安裝，使用Pivotal準備的Harbor Tile去做部署，這樣佈出來的Harbor會在BOSH的管控保護之下。如果不想透過Harbor Tile安裝的話，也可以使用另一種方式自己手動裝(一般是透過docker)，安裝方式可以參考Github，這兩種方式都是可以的。Harbor除了能提供一般Container Registry的服務之外，還能夠整合開源專案Notary以及Clair。Notary是CNCF的專案，主要是提供Content Trust簽章服務，確保Image內容不被串改，而Clair能夠針對Image提供靜態分析，根據已知的CVE庫來找出Image淺在的漏洞。  Harbor Tile除了多了一些BOSH Agent以外，其他部分都跟手動裝的版本一模一樣。6. PKS Client目前PKS以及BOSH都尚未提供GUI介面來做操作，因此都必須透過CLI來做操作。通常會找一台主機安裝所需要的CLI，這台機器我們就稱為PKS Client，PKS Client並沒有限制一定要甚麼作業系統或是多少資源，就只要能安裝CLI以及存取到PKS環境就可以了。7. NSX-TNSX-T是VMware旗下Networking Virtualization產品，與NSX-V不同，NSX-T是完全獨立的原件，它並沒有限制一定要整合vSphere或是建置在vSphere環境上。像筆者就看過OpenStack整合NSX-T的。另外NSX-T也支援Container環境。NSX-T在Enterprise PKS環境中同樣不是必須的，也完全與Pivotal無關係(因此沒有甚麼NSX-T Tile xD)，當然你可以不採用NSX-T，直接使用vSphere環境的vSS或是vDS提供給Enterprise PKS環境網路，但是筆者認為PKS要整合NSX-T才能完全增強PKS的功能(可以參照比較表)，因為NSX-T除了提供SDN功能之外，還提供了非常強大的微分割，微分割的單位可以縮小到pod跟pod之間，也就是管理者可以自定義ACL給不同的pod，進而達到強大的隔離性。雖然NSX-T很強大且也可以完全整合PKS，但是筆者認為NSX-T還是一個不太穩定的產品，可能剛出來不久還有許多問題跟功能尚未完成，感覺還有一段路要走。安裝Enterprise PKS目前安裝方式都是使用PCF Ops Manager來做安裝，由於步驟繁多，因此這裡不多加闡述，有興趣可以參考官方文件 - https://docs.pivotal.io/runtimes/pks/1-4/index.htmlPreparation:  vSphere Environment  vCenter Server  NSX-T (Optional)  Ops Manager OVA  PKS Tile  Harbor Tile (Optional)  BOSH/PKS/Ops Manager CLIPKS支援Cluster 版本Release Notes - https://docs.pivotal.io/runtimes/pks/1-4/release-notes.html#1.4.1Enterprise PKS目前最新版是1.4.1，此版所對應的Kubernetes版本是v1.13.5，目前尚無法選擇要部署的Kubernetes版本，因為BOSH部署方式是使用VM Template，安裝套件都是已經包好的了，因此如果想要使用新一點版本的Kubernetes，只能等到下次PKS更新之後了。參考資料  Pivotal.io - https://pivotal.io/  Rancher - https://rancher.com/  OpenShift - https://www.openshift.com/  IBM Cloud Private - https://www.ibm.com/tw-zh/cloud/private  BOSH - https://www.bosh.io/docs/  Harbor - https://github.com/goharbor/harbor  Notary - https://github.com/theupdateframework/notary  Clair - https://github.com/coreos/clair  NSX-T Data Center Installation Guide  VMware Cloud PKS - https://cloud.vmware.com/vmware-cloud-pks  Enterprise PKS document -https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/nsxt_24_install.pdfhttps://docs.pivotal.io/runtimes/pks/1-4/index.html  VMware 發佈 VMware Essential PKS - https://blogs.vmware.com/vmware-taiwan/2019/03/01/vmware-%E7%99%BC%E4%BD%88-vmware-essential-pks/  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "2019 iThome資安大會筆記",
    "url": "/blog/2019-ithome-cyber-sec-notes/",
    "categories": "Security",
    "tags": "conference",
    "date": "2019-05-27 07:17:07 +0800",
    





    "snippet": "這篇主要是補上今年3月份參加iThome資安大會的一些筆記跟小小心得。今年的資安大會與往年一樣都在台北國際會議中心舉辦，不過由於我第一天有事情，因此今年只有參加到後面兩天，挺可惜的，不過後面兩天也蠻多精彩的演講(雖然大部分還是推銷產品居多)，以下就是我的一些小小筆記，如果想暸解更細部的話，目前簡報已經都釋出在官網上了，可以去參考～議程: https://cyber.ithome.com.tw/agenda3/20Keynote 正面迎戰內部威脅，公司被害還是員工被駭?!  「研發部門是企業命脈，卻最難管理」，鎖太多權限可能導致開發人員沒辦法安裝套件或是一些撰寫的一些程式功能無法執行，但是開發人員有可能會藉由一些方式(如IDE)，使用看起來合法的操作來將企業資料攜出。  為了避免這樣，精品科技開發的產品能夠讓IT人員針對特定IDE去所權限，例如可以設定visual code所執行的CMD沒辦法用來上網或是沒辦法執行敏感指令(copy &amp;amp; paste)，正常情況下的CMD沒事，但是只要是從IDE叫出來的CMD就鎖權限。另外也可擋掉IDE上面的code在執行某些敏感的動作。  除了IDE以外，另外也可以限制如Office這種軟體，權限可以設定的很彈性，例如可以設定只能把文字從外部複製貼上到Word，但是不能從Word把資料複製出來等。  原理推測是透過在端點執行Agent直接去對Windows底層的API去做阻擋，因為不管什麼操作都還是要靠Windows 底層的API來完成，因此直接去鎖底層就可以達到這樣的管理。Cyberlab 趨勢科技 Target ransom  實機課程，由於禁止將講義跟參考資料帶出，因此只能簡單概述實機內容。  現在勒鎖軟體已經不一定要使用一些非法的程式，許多駭客已經開始使用「正當合法軟體」來作加密的動作(如winrar)，這樣可以避免防毒的偵測。  一般企業中勒鎖病毒都以為只要把中的那台還原或是把資料從備份倒回來就好，但是這樣治標不治本，因為駭客還是存在公司裡，也許他是透過內網裡某台跳板機來攻擊目標，但往往IT人員都只會把焦點放在被攻擊的目標上，以為是那台被駭。要如何追查APT攻擊怎麼造成的對於IT人員來說是非常的困難，透過趨勢科技的APEX產品，就可以幫助IT人員方便的查找問題。  實機操作就是試著扮演駭客透過跳板機去打下AD Server，然後再試著扮演網管人員去追查攻擊流程。學員扮演角色：駭客:Step 1: 首先連到企業的一個網站Step 2: 透過聯絡我們上傳照片功能，上傳Webshell到網站。Step 3: 直接在網站上執行Webshell，新增一個使用者並提權為管理者，然後了解一下Web Server相關資訊(hostname、Web server version…)Step 4: 發現Web Server是Windows Server IIS。Step 5: 嘗試能不能遠端桌面，不能，可能是防火牆擋住或是沒開RDP功能。Step 6: 透過Web shell關閉防火牆功能以及開啟RDPStep 7: 在測試一次遠端桌面，成功進到Web Server。Step 8: 接著要使用procdump跟駭客工具minikatz來取得Web Server上跑的服務的使用者帳密。Step 9: 由於minikatz會被大部分防毒給擋掉，因此不能直接就把minikatz上傳到Web Server，因此這裡只上傳procdump。Step 10: procdump是合法的軟體，就是把process dump出來，因此在Web Server上執行沒問題，我們直接將proces資訊dump吃來，然後把Output傳到駭客的電腦。Step 11: 在駭客電腦執行minikatz分析process dump結果，成功發現kerberos帳號密碼以及服務IP(AD Server)。Step 12: 測試看看能不能直接透過網路芳鄰輸入IP位置跟帳號密碼連到AD Server的admin$目錄，發現可以成功到admin$目錄。Step 12: 將預寫好的勒鎖軟體上傳到Web Server，由於是透過winrar去加密程式，因此不怕防毒偵測。Step 13: 在Web Server執行勒鎖軟體，加密AD Server admin$資料夾。Step 14: 加密完成，AD Server服務已停止。學員扮演角色：IT人員:Step 1: 發現AD Server被加密，要開始查找問題是怎麼發生的。Step 2: 連入趨勢科技的產品Apex Web GUI來查找問題。Step 3: 首先先隨便在AD Server找一個被加密的檔案名稱，然後透過檔案名稱去搜尋。Step 4: APEX找出這個檔案存在於哪一台主機(AD Server)，以及他的LOG，透過LOG可以看到他是被什麼Windows指令加密的(rar.exe -df   -p)還有是哪個使用者帳號執行的、從哪個檔案執行的以及執行時間，看到加密的密碼，網管人員可以松一口氣，表示至少可以還原檔案了。Step 5: APEX上可以使用LOG產出Root Cause Analysis(RCA)圖，類似關聯圖。關聯圖上面顯示跟那段指令有相關的檔案:PsExec.exe -&amp;gt; encrypt.exe -&amp;gt; cmd.exe -&amp;gt; rar.exe -&amp;gt; &amp;lt;被加密的檔案&amp;gt;從關聯圖可以看出，有人透過PsExec程式來從別台主機遠端在AD Server上執行encrypt.exe作加密的動作。Step 6: 接下來要找哪一台主機的log有encrypt.exe這個檔案的紀錄。一樣到APEX GUI透過檔名搜尋Step 7: 突然搜到除了AD Server以外，還有一台WEB Server一樣有執行這個檔案的紀錄(這個是執行紀錄，就算檔案刪掉也沒用，刪掉的指令也一樣完全都會被記錄進來)，另外還發現是WEB Server奇怪的帳號(剛剛駭客用webshell新增的使用者，一樣駭客刪掉使用者也沒有用，因為一舉一動都被記錄下來)執行encrypt.exe的。Step 8: 產出RCA圖，可以看到encrypt.exe的原檔名Explorer.exe -&amp;gt; randsom.exe(原檔名) -&amp;gt; PsExec.exe -&amp;gt; encrypt.exe -&amp;gt; cmd.exe -&amp;gt; ...可以看到Explorer.exe執行randsom.exe，因此可以推斷WEB Server就是源頭也就是跳板機。Step 9: 回到APEX WEB GUI，以主機為單位，直接去叫出WEB Server上在這段期間執行所有的動作，因此駭客所做的每一步都直接顯示在頁面上(用webshell執行的所有動作)。Step 10: 結束。心得:APEX與前面keynote的原理一樣，一樣要在企業的所有機器裝Agent，這個Agent就是趨勢科技的防毒軟體，只是如果要採用agent收集功能，要加授權就可以，這個Agent一樣會去hook windows底層的API，所以每一步驟都完全被記錄下來，駭客要關掉Agent是非常困難的，Agent會用密碼加密，且可能會被設定為唯獨，因此可能不會受勒鎖軟體影響。這個agent會完全沒有隱私，但PC所有的一舉一動都會記錄下來，所以以前常聽到的駭客入侵後要清除足跡，在這種情況下幾乎是完全不管用的，因為就連『清除』這個動作也會被記錄起來。Android 惡意程式動態解殼研究  一般來說Android開發者會對程式碼進行加殼，來防止反編譯。  加殼方法：          混淆Code(缺點是標準API不能混淆)      Dex文件加密      Header修改      Dex data加密      Method動態加解密      VMP (Virtual Protect)        有些開發者會先把code加密，然後故意把不重要的檔案做混淆，讓反編譯的人以為混淆的檔案就是code，然後花心力在處理混淆，殊不知真正的code被加密放在別的地方。資訊安全中的人工智能對抗  近年來大家很流行使用Machine Learning來training model去對資安攻擊做偵測，但是也衍伸了一種針對Machine Learning Model進行攻擊的「Adversarial Machine Learning」(AML)。  AML是去欺騙Model，使用混淆或是污染的方式來攻擊弄壞Model。例如：Model可以分出狗跟貓，但假如說駭客做一個像貓又像狗的照片(自然界不存在，也就是非正常的Data)，然後餵給Model，Model可能就會造成誤判。另外一種方式是圖片是狗，但是某一個pixel故意放烤麵包機，以人的肉眼來看看不出來，但是Model在判別時，就會造成錯誤，可能會誤判。  除圖像的以外，垃圾郵件的偵測也可以使用AML，例如在垃圾郵件裡面故意塞一段正常文字，Model可能就會以為這是正常的郵件。或是郵件裡面的某些文字故意換成同義詞，這樣可能也可以繞過垃圾郵件判別。  絕大部分的Model都不太可能百分之百不被騙或是混淆，如果一個Model完全不會被混淆，那個Model也沒有AML的價值。  AML攻擊手法可以分成兩種：          Evasion Attack: 製作特製的data來騙或繞過Model，又可分成黑箱跟白箱，黑箱是駭客不知道Model長怎樣，只能不斷透過Output去猜測，白箱是指駭客已經事先了解Model規則。      Poision Attack: 去破壞Model，例如有些chat bot採用online traing機制，一邊聊天一邊學，但只要一直餵給他特定的data，就可以讓Model壞掉，學奇怪的東西或是誤判。        防禦方式：          Evasion Attack: 駭客一定要有方法去試Model Output，因此只要偵測是否有人在短時間內大量測試或是人工簡單看一下是否有不尋常非自然得data，如果有就BAN掉。      Model retrain：一但發現Model分析資料不準，就馬上修正Model並重新training。retrain又可分成主動式跟被動式，主動式是企業內部red/blue team主動去攻擊Model，然後修正Model。被動是等被攻擊了，才Retrain。      駭客如何利用公開工具在內部網路中暢行無阻iThome報導 - https://www.ithome.com.tw/news/129486?fbclid=IwAR2rBpZx6r-fWXgmsTupgUrzkWsOiCunvCleq5oyfONtz6zyd3aQ1Zr1Abg  紅隊演練 vs 滲透測試          紅隊演練：駭客思維出發、全面且廣泛、目的是竊取企業資料      滲透測試：在特定範圍、針對特定目標、目的是挖掘系統漏洞        攻擊鍊:    目標偵查 -&amp;gt; 武器研製 -&amp;gt; 發動攻擊 -&amp;gt; 維持控制 -&amp;gt; 內網滲透 -&amp;gt; 偷取資料        目標偵查: Recon-Ng工具  武器研製: Metasploit(產生惡意巨集文件)  維持控制：安裝後門  內網滲透： BloodHound(能夠將AD Server網域內的元件以圖性化顯示並且提供攻擊路徑)、Responder(針對LLMNR或NBT-NS,MDNS謝進行poisoning attack)  偷取資料：dnscat2(DNS Tunnel)、icmpsh(ICMP Tunnel)。  防禦方對策          研究公開工具，將其特徵加入資安產品      禁止不安全的巨集或是不常見的腳本運行(hta,vbs…)。      使用公開工具掃網路環境開啟服務並關閉未使用的功能。      檢視不安全的ACL配置      檢視DNS伺服器的解析方式      3/21KEYNOTE【Live Demo】工業控制 Testbed 與資安攻防研究  近幾年工業製造的資安問題也慢慢開始被重視。  講者現場Demo一個模擬火車環境，駭客入侵鐵道管理系統，然後將火車引導到斷軌的地方。  攻擊手法為：    滲透至內網-&amp;gt; 中間人攻擊 -&amp;gt; 封包側錄或解析 -&amp;gt; 串改封包或是發放假封包給控制端        台灣工控設備有10546個暴露於網際網路(具有真實調查資料)，且大部分都是走HTTP協定，非常不安全，暴露的產業有能源業、大專院校、政府機關、停車場業者、鋼鐵製造業、飯店大夏管理等。  工業控制網路防護自我健康檢查          資產盤點：                  是否已辨識關鍵基礎設施？          是否進行風險管理與評估？          使否檢視網段劃分與工業控制網路邊界？          是否檢視網路架構設計邏輯？                    ICS系統帳號管理：                  是否制定帳號鎖定、管理政策？          是否查找、刪除任何預設的特權帳號及密碼？          是否要求使用強密碼和多因素身份驗證？          是否限制特權帳號數量？尤其第三方供應商          是否要求OT場域人員定期更換密碼                    OT網路隔離性(ioslate)檢視                  是否可以直接由網際網路存取ICS？          是否可以直接由IT網路存取ICS?          是否有嚴謹之傘端存取管理政策？          防火牆是否已隔離所有需保護的ICS網路和設備。                    KEYNOTE善用駭客思維：如何聯合白帽駭客共同加強資安防禦能量  紅隊演練不應該事先告知，且紅隊會一直學習新的攻擊技術，增強攻擊能力，這樣可以考驗藍隊的應對處理機制。  企業產品安全保護方式(按照順序)：          Code &amp;amp; architecture review: 針對工程師或是員工上風險評估以及資訊安全概念的相關課程。工程師內部針對code去做review，看有沒有安全風險。      動＆靜態程式測試      紅隊演練：企業內部團隊找漏洞。      開啟Bug Bounty：讓全世界的白帽駭客一起來找漏洞。        紅隊演練的好處：          能夠讓企業了解產品的弱點及漏洞面向。      能夠讓藍隊增強企業安全的防守。      允許管理層衡量安全解決方案的投資。      能夠增加攻擊的成本，讓駭客攻擊更加困難。      資安脫口秀  甲方不應該看哪家廠商設備數字或成績漂亮就選擇他，應該是根據自身需要來選擇，可以整理近幾年公司遇到的資安事件，然後再跟乙方做討論，這樣才能選擇到公司可用的解決方案。突破困境：資安開源工具之應用分享  簡報 - https://www.slideshare.net/jasoncheng7115/20190321-137504140?fbclid=IwAR26IO1-XOw_0xPIX2jPZB859H2B9XC8Xt35WxO0EZVvx9yEW6ZL7TTYST8            開源工具      解決方案                  Proxmox      開源伺服器虛擬化管理平台              LibreNMS      開源裝置與服務狀態監視              Open-audIT      開源IT資產管理系統              Graylog      開源事件記錄管理與分析              FreeNAS      開源儲存伺服器系統              Duplicati      開源資料備份系統              PacketFence      開源網路存取控制系統              WSO2 IoT      開源行動裝置管理(MDM BYOD管理)              OpenVAS      開源弱點檢測管理平台              MobSF      開源APP安全測試平台              SonarQube      開源程式碼檢測平台              Proxmox MG      開源郵件閘道伺服器        開源套件選擇要點          版本更新: 可以查看更新日期      活躍程度：可以知道這個專案到底有沒有在維護      商業支援：是否有付費版跟開源版，通常有付費版撐腰的比較好。      留意授權問題(GPL,BSD, Apache…)        Open Hub - 開源專案安全檢測與授權建議解密 HTTPS 雲端服務的美麗與哀愁: 側錄 / 備份 / 防毒 / 稽核  TLS提供了實質性的好處，但是卻也增加了分析流量的困難。  部分國家是禁止對HTTPS做解密，因為會有隱私權問題。  通常金融業是不能對HTTPS做解密，因為資料過度敏感。  有些軟體例如Line或是Messenger，沒辦法做解密，因為這些程式只要發現憑證被改就會被擋掉。心得: 大部分的HTTPS解密都是透過proxy來做到，client端裝agent來換掉憑證，然後proxy端做解密的動作，接著再由proxy去跟Web Server去做連線，這樣就可以取得HTTPS的內容。廠商(只有部分)郵件過濾及郵件安全：  Proofpoint郵件伺服器及郵件安全  Openfind特權帳號監控管理  CyberarkHTTPS流量管理監控(解密HTTPS)  L7Ntwork  F5雲端安全  Tufin  F-Secure透過DNS來防護  Cisco Umbrella端點檔案加密(為重要檔案加密)  中華電信SecurBoxDDoS防護  威睿科技 GenieATM(透過設備將流量導到F5那些去做清洗，他們只做導向的動作而已)  Arbor  AkamaiLog管理  ALog整合型安全風險管理平台  tenable  IBM SecurityBirdman新創公司  CYCARRIER其餘學習  以往對付DDoS，廠商都是直接放一台自家設備在Gateway，當攻擊發生時設備將流量導向到Cloud Scrubbing Center去做清洗，但是這樣子對Client端還是有很大得負擔，因此發現今年許多處理DDoS的廠商，在Redirect的部分改用了BGP forwarding或是DNS Forwarding，直接在源頭就將流量導向到Scrubbing Center，這樣就不會增加Client的負擔。  市面上大部分的IP Cam都是換湯不換藥，外殼是自己設計，但是晶片可能就採用大陸晶片，這種認證通常都很脆弱，只要使用一些現有的APP就可以掃到IP cam然後免認證登入，因此在買IP cam的時候，最好選擇有通過『 IP Camera 場域實驗室』認證的IP Cam。  電影裡騙過管理者IP CAM畫面現實是做得到的，只要透過arp spoofing先去欺騙IP CAM管理器，這樣管理器就會以為駭客的電腦才是IP CAM，然後駭客再送假訊號(畫面正常的影片)給管理器，這樣管理器那邊就會一直看到是正常的畫面。  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  },
  
  {
    "title": "SSH Tunnel介紹",
    "url": "/blog/ssh-tunnel-introduction/",
    "categories": "Linux",
    "tags": "ssh",
    "date": "2019-05-23 08:23:25 +0800",
    





    "snippet": "由於最近碰到一些特殊網路情境必須使用到SSH Tunnel，因此花點時間複習了一下。SSH Tunnel是個非常好用的技術，可以在一些比較安全或封閉的網路將流量透過SSH Protocol傳輸出去。使用SSH Tunnel一定要準備一個與Client端不同網路的Remote Server當作跳板機，其原理類似Port Forwarding的概念，在Client以及Remote Server之間建立一個SSH Tunnel，然後將特定的服務全部透過這個Tunnel來傳送，就可以達到加密及穿透的效果。SSH Tunnel又可分成兩種:  Local Tunnel (又稱SSH Local Forwarding)  Remote Tunnel (又稱SSH Remote Forwarding)這兩種差別其實就是要從哪一端將流量透過SSH Tunnel傳送出去，一個是從local端傳送給Remote端，一個是從Remote傳回來給local。接下來會針對這兩種Tunnel做細部解釋以及適用的情境。Local TunnelLocal Tunnel主要是從Local端(Client端)，將Client端特定服務的流量透過SSH傳給Remote Server，再透過Remote Server傳出去給Application Server。其使用的情境可以分成兩種：一種是想要連到特定的服務，但是卻不想被網管監測到流量，就可以使用SSH來傳送流量出去，這樣網管只能看到SSH加密的流量，沒辦法看到內容。另一種是公司防火牆有限制員工不能連到特定服務或網站，也可以將流量包到SSH裡面來繞過防火牆出去(前提是防火牆沒有檔SSH服務)。指令(此指令需在Client端執行)：$ ssh -NfL &amp;lt;local listening IP&amp;gt;:&amp;lt;local listening port&amp;gt;:&amp;lt;application ip&amp;gt;:&amp;lt;application port&amp;gt; &amp;lt;Remote Server&amp;gt;# Example$ ssh -NfL localhost:1234:&amp;lt;web server ip&amp;gt;:80 user@&amp;lt;remote server ip&amp;gt;  -N 代表不要開起shell code模式-f 代表在背景執行-L 代表Local Tunnel&amp;lt;local listening IP&amp;gt; 要在Client上監聽的IP。&amp;lt;local listening port&amp;gt; 要在Client上監聽的Port，可自行定義。&amp;lt;application ip&amp;gt; 要存取的服務IP&amp;lt;application port&amp;gt; 要存取的服務port這邊意思是假如Client上有任何Request要傳送到&amp;lt;local listening IP&amp;gt;:&amp;lt;local listening port&amp;gt;，Client就會將他轉送到SSH Tunnel來傳給Remote Server，Remote Server收到流量後，會把封包轉送到&amp;lt;application ip&amp;gt;:&amp;lt;application port&amp;gt;，因此從Client端到Remote Server端之間的路是透過SSH傳送的(加密連線)。Client &amp;lt;--SSH Tunnel--&amp;gt; Remote Server &amp;lt;--Internet--&amp;gt; Application Server  請注意這邊的&amp;lt;local listening  port&amp;gt;跟&amp;lt;application port&amp;gt;與SSH服務使用到的Port完全沒有任何關係，預設SSH Server使用的Port還是22，然後Client端是亂數產生。如果Remote Server的SSH Port不是22的話，那就必須在指令後面加上 -p &amp;lt;port number&amp;gt;  Example:ssh -NfL localhost:1234:&amp;lt;web server ip&amp;gt;:80 user@&amp;lt;remote server ip&amp;gt; -p 3000  這邊需要注意的是&amp;lt;local listening IP&amp;gt;可以打也可以不打，預設是localhost(127.0.0.1)，如果要監聽在不同的IP，需要針對sshd_config做設定，在稍後會做說明。情境1想要在公司使用ptt(ssh bbsu@ptt.cc)，但是不想被網管發現。角色:  Client: 公司個人電腦or筆電，需要可以使用SSH指令。  Remote Server: 當作跳板的機器，需要有SSH Server服務，且必須位於公司網路之外。Client必須連得到它。  ptt.cc: 要連線的Application Server。Step  在Client上Console執行Local Tunnel。    $ ssh -NfL 1234:ppt.cc:23 &amp;lt;Remote Server&amp;gt;            在Client端檢查是否有成功建立起Tunnel    $ netstat -plnt $ ps -ef | grep ssh        接下來就可以透過Client連到ptt    $ ssh bbsu@localhost -p 1234            如果要關掉Tunnel，只需要在Client上面執行以下指令：    $ ps -ef | grep ssh$ kill &amp;lt;ssh tunnel 那條服務的PID&amp;gt;        說明在這個情境中，當Client收到要通往localhost:1234的Request時，就會將它丟到SSH Tunnel傳送給Remote Server，Remote Server收到後再把它丟到ptt.cc:22，當封包回來也是一樣，只是就反過來，Remote Sever將Response透過SSH Tunnel丟回給Client，Client再將封包從SSH Tunnel丟給1234 port。  情境2公司防火牆擋掉xxx網站，要如何才能繞過防火牆連到網站角色:  Client: 公司個人電腦or筆電，需要可以使用SSH指令。  Remote Server: 當作跳板的機器，需要有SSH Server服務，且必須位於公司網路之外，Client必須連得到它。  Web Server: 要連線的Application Server。Step  在Client上Console執行Local Tunnel。    $ ssh -NfL 80:&amp;lt;web server&amp;gt;:80  &amp;lt;Remote Server User&amp;gt;@&amp;lt;Remote Server IP&amp;gt;        在Client端檢查是否有成功建立起Tunnel    $ netstat -plnt $ ps -ef | grep ssh        接下來就可以透過Client上的瀏覽器連到網站(輸入http://localhost)    #除了瀏覽器之外，也可以使用curl測試$ curl http://localhost        如果要關掉Tunnel，只需要在Client上面執行以下指令：    $ ps -ef | grep ssh$ kill &amp;lt;ssh tunnel 那條服務的PID&amp;gt;      說明在這個情境中，當Client收到要通往localhost:80的Request時，就會將它丟到SSH Tunnel傳送給Remote Server，Remote Server收到後再把它丟到&amp;lt;web server&amp;gt;:80，封包回來得時候也是一樣，只是順序反過來。這邊需要注意的是，如果是要Redirect 443 port，可能會因為憑證被換掉而導致憑證錯誤，因此這種情境不太建議使用在有TLS加密的Web Server，純粹拿來測試就好。另外如果Web Server是在Load Balancer後面，那這樣可能也會導致Local Tunnel無法成功，這邊不太確定為什麼，有可能是因為導到後面後，IP就不是原本設定Tunnel的那個Web Server IP，因此流量就不會正常的走SSH Tunnel。Remote TunnelRemote Tunnel是我比較常用的Tunnel方式，因為可以達到類似於VPN的功能，來存取內網的服務，可以應用在很多種情境上。Remote Tunnel是指從Remote端(Remote Server端)，將特定服務的流量透過SSH傳回給Client端上的服務。指令(此指令需在Client上執行)：$ ssh -NfR &amp;lt;remote listening IP&amp;gt;:&amp;lt;remote listening port&amp;gt;:&amp;lt;client listening ip&amp;gt;:&amp;lt;client listening port&amp;gt; &amp;lt;Remote Server&amp;gt;# Example$ ssh -NfR localhost:1234:localhost:80 user@&amp;lt;remote server ip&amp;gt;  -N 代表不要開起shell code模式-f 代表在背景執行-R 代表Remote Tunnel&amp;lt;remote listening IP&amp;gt; 要在Remote Server上監聽的IP&amp;lt;remote listening port&amp;gt; 要在Remote Server上監聽的Port，可自行定義。&amp;lt;client listening ip&amp;gt; Client上面服務監聽的IP&amp;lt;client listening port&amp;gt; Client上面服務port這段指令意思是任何送到Remote Server上&amp;lt;remote listening IP&amp;gt;:&amp;lt;remote listening port&amp;gt;的Request，Remote Server都會將他透過SSH Tunnel傳送到給Client，Client再將Request丟給自己的&amp;lt;client listening ip&amp;gt;:&amp;lt;client listening port&amp;gt;服務。外部主機 --SSH--&amp;gt; Remote Server &amp;lt;--SSH Tunnel--&amp;gt; Client  請注意這邊的&amp;lt;remote listening  port&amp;gt;跟&amp;lt;client listening port&amp;gt;與SSH服務使用到的Port完全沒有任何關係，預設SSH Server使用的Port還是22，然後Client端是亂數產生。如果Remote Server的SSH Port不是22的話，那就必須在指令後面加上 -p &amp;lt;port number&amp;gt;  Example:ssh -NfR localhost:1234:localhost:80 user@&amp;lt;remote server ip&amp;gt; -p 3000  這邊需要注意的是&amp;lt;remote listening IP&amp;gt;可以打也可以不打，預設是localhost(127.0.0.1)，如果要監聽在不同的IP，需要針對sshd_config做設定，在稍後會做說明。一般情境公司的PC是在內網裡面，且是虛擬IP，有沒有辦法不透過VPN，從公司外面SSH連回來自己的PC？or公司的防火牆擋掉外對內的連線，因此沒辦法從外部透過SSH連回公司裡自己建置的SSH Server，是否有辦法不透過VPN，從公司外面SSH連回來SSH Server？角色:  Client: 公司內部的主機，也就是希望能從公司外部透過SSH連回的SSH Server，需要可以使用SSH指令。  Remote Server: 當作跳板的機器，需要有SSH Server服務，且必須位於公司網路之外，Client要能連得到它。  外部電腦: 位於公司外部的電腦，必須能連得到Remote Server。Step  在Client端執行Remote SSH Tunnel。    $ ssh -NfR 1234:localhost:22  &amp;lt;Remote Server User&amp;gt;@&amp;lt;Remote Server IP&amp;gt;            在Remote Server端以及Client端檢查是否有成功建立起Tunnel    Client     ps -ef | grep ssh        Remote Server     netstat -plnt         接下來先透過外部電腦連到Remote Server。    # 在外部電腦上執行$ ssh &amp;lt;Remote Server User&amp;gt;@&amp;lt;Remote Server IP&amp;gt;        透過Remote Server反向連回Client。    # 在Remote Server上執行$ ssh localhost -p 1234        如果要關掉Tunnel，只需要在Client上面執行以下指令：    $ ps -ef | grep ssh$ kill &amp;lt;ssh tunnel 那條服務的PID&amp;gt;      說明在這個情境中，主要是先在Client開啟Remote Tunnel，然後Remote Tunnel會在Remote Server上監聽1234 port，當有Request從1234 port來的話，Remote Server就會透過SSH轉送回Client，Client收到後再將這個Request轉送給自己的22 Port。設定讓外部能存取SSH Tunnel預設SSH Tunnel是不能監聽在localhost以外的IP，因此每次使用Remote Tunnel就一定要先連到Remote Server才能反連回去，這樣不太方便，因此我們可以在SSH Server上面允許SSH Tunnel可以監聽在其他Port。  到Remote Server上開啟sshd_config    $ vim /etc/ssh/sshd_config        找到GatewayPorts選項並設成yes，如果沒有這個選項可以自己加上去。    GatewayPorts yes        重啟SSH服務    $ systemctl restart sshd.service        這樣就可以將SSH Tunnel監聽在任何IP上    # Local Tunnel$ ssh -NfL 0.0.0.0:1234:&amp;lt;web server ip&amp;gt;:80 user@&amp;lt;remote server ip&amp;gt;$ ssh -NfL xx.xx.xx.xx:1234:&amp;lt;web server ip&amp;gt;:80 user@&amp;lt;remote server ip&amp;gt;...# Remote Tunnel$ ssh -NfR 0.0.0.0:1234:localhost:80 user@&amp;lt;remote server ip&amp;gt;$ ssh -NfR xx.xx.xx.xx:1234:localhost:80 user@&amp;lt;remote server ip&amp;gt;...      設定外部能存取後，就可以結合各式各樣的應用，例如：Reverse Proxy透過Remote Server反向連回公司PC上的Web Server。$ ssh -NfR 0.0.0.0:80:localhost:80 user@&amp;lt;remote server ip&amp;gt;如此一來不需要連到Remote Server，只要在任何能存取到Remote Server的主機使用瀏覽器連http://&amp;lt;remote server ip&amp;gt;或是執行curl http://&amp;lt;remote server ip&amp;gt;就可以連到公司的web server。RDP透過Remote Server反向連回公司PC上的遠端桌面服務。$ ssh -NfR 0.0.0.0:3389:localhost:3389 user@&amp;lt;remote server ip&amp;gt;如此一來不需要連到Remote Server，只要在任何能存取到Remote Server的主機上使用遠端桌面連到&amp;lt;remote server ip&amp;gt;:3389，就可反向連到公司PC上的遠端桌面服務。  這邊都只有使用Remote Tunnel來當作範例，但是其實Local Tunnel也可以把&amp;lt;local listening IP&amp;gt;設定成監聽任何IP，只是目前比較少碰到需要把Local Tunnel開放外部存取這種情況，因此這裡就不特別闡述，有興趣可以自行測試看看。如何防止SSH TunnelSSH Tunnel防範的方法有很多，這邊目前先列出幾種比較常聽到的，之後如果還有學習到別的方法再補充上來。  SSH Server關閉SSH Tunnel服務，開啟sshd_config設定AllowTcpForwarding no。這樣可以防止別人用你的SSH Server當SSH Tunnel跳板機。  在防火牆直接擋掉SSH服務，不管內對外，外對內都擋。(曾經真的有遇到類似的案例，只是是限制特定的主機，例如給guest使用的或是一些非資訊技術相關的End User用的，並不是真的全公司的主機都擋)。  使用一些端點安全防護的產品直接禁止客戶使用SSH Tunnel指令或是SIEM產品去trace哪個使用者使用了Tunnel。參考資料  SSH Tunnel - Local and Remote Port Forwarding Explained With Examples - https://blog.trackets.com/2014/05/17/ssh-tunnel-local-and-remote-port-forwarding-explained-with-examples.html  How to make ssh tunnel open to public? - https://superuser.com/questions/588591/how-to-make-ssh-tunnel-open-to-public  Securing Your SSH Server - http://download.asperasoft.com/download/docs/proxy/1.4.0/admin_linux/webhelp/dita/securing_ssh_server.html  文章內容的轉載、重製、發佈，請註明出處: https://blog.phshih.com/"
  }
  
]

